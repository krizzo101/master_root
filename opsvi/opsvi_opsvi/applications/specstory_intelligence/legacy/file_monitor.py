"""
Real-Time SpecStory File Monitoring System
Watches directories for new/modified SpecStory files and queues them for processing
"""

import asyncio
import hashlib
import json
import os
import re
from datetime import datetime
from pathlib import Path

import aiofiles
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer


class SpecStoryFileWatcher(FileSystemEventHandler):
    """Enhanced file system event handler for SpecStory files"""

    def __init__(self, processor_queue: asyncio.Queue, config: dict, loop=None):
        super().__init__()
        self.processor_queue = processor_queue
        self.config = config
        self.processed_files: set[str] = set()
        self.file_hashes: dict[str, str] = {}
        self.loop = loop or asyncio.get_event_loop()

        # Load file patterns from config or external file
        pattern_list = config.get("file_patterns")
        if not pattern_list:
            config_path = config.get("pattern_config_path", "file_monitor_config.json")
            if os.path.exists(config_path):
                try:
                    import json

                    with open(config_path) as f:
                        pattern_list = json.load(f).get("file_patterns", [])
                except Exception as e:
                    print(f"‚ö†Ô∏è Error loading file patterns from {config_path}: {e}")
                    pattern_list = []
        if not pattern_list:
            # Fallback to old defaults
            pattern_list = [
                r"\.specstory/history/.*\.md$",
                r".*_\d{4}-\d{2}-\d{2}_\d{2}-\d{2}Z-.*\.md$",
                r".*\.specstory\.md$",
            ]
        self.specstory_patterns = [re.compile(p) for p in pattern_list]

        # Required header patterns for validation
        self.header_patterns = [
            re.compile(r"^<!-- Generated by SpecStory -->$"),
            re.compile(r"^# .+ \(\d{4}-\d{2}-\d{2} \d{2}:\d{2}Z\)$"),
        ]

        self.content_indicators = [
            "_**User**_",
            "_**Assistant**_",
            "<function_calls>",
            "<function_results>",
            "<think><details><summary>",
        ]

    def on_created(self, event):
        """Handle file creation events"""
        if not event.is_directory:
            try:
                asyncio.get_running_loop()
                asyncio.create_task(self._handle_file_event(event.src_path, "created"))
            except RuntimeError:
                # Not in main thread/event loop
                asyncio.run_coroutine_threadsafe(
                    self._handle_file_event(event.src_path, "created"), self.loop
                )

    def on_modified(self, event):
        """Handle file modification events"""
        if not event.is_directory:
            try:
                asyncio.get_running_loop()
                asyncio.create_task(self._handle_file_event(event.src_path, "modified"))
            except RuntimeError:
                asyncio.run_coroutine_threadsafe(
                    self._handle_file_event(event.src_path, "modified"), self.loop
                )

    async def _handle_file_event(self, filepath: str, event_type: str):
        """Process file events asynchronously"""
        try:
            if await self._is_specstory_file(filepath):
                await self._queue_for_processing(filepath, event_type)
        except Exception as e:
            print(f"‚ö†Ô∏è Error handling file event for {filepath}: {e}")

    async def _is_specstory_file(self, filepath: str) -> bool:
        """Determine if file matches the configured patterns (no header/content checks)"""
        path = Path(filepath)
        # Only check filename patterns now
        return any(pattern.search(str(path)) for pattern in self.specstory_patterns)

    async def _queue_for_processing(self, filepath: str, event_type: str):
        """Add file to processing queue with deduplication"""
        file_hash = await self._calculate_file_hash(filepath)

        # Check if we've already processed this exact content
        if filepath in self.file_hashes and self.file_hashes[filepath] == file_hash:
            return  # No changes, skip

        self.file_hashes[filepath] = file_hash

        processing_task = {
            "filepath": filepath,
            "filename": Path(filepath).name,
            "event_type": event_type,
            "file_hash": file_hash,
            "detected_at": datetime.utcnow().isoformat(),
            "file_size": Path(filepath).stat().st_size,
            "priority": "high" if event_type == "created" else "normal",
        }

        await self.processor_queue.put(processing_task)
        print(f"üîç Queued SpecStory file: {Path(filepath).name} ({event_type})")

    async def _calculate_file_hash(self, filepath: str) -> str:
        """Calculate SHA-256 hash of file content"""
        hash_md5 = hashlib.sha256()
        try:
            async with aiofiles.open(filepath, "rb") as f:
                async for chunk in f:
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return f"error_{datetime.utcnow().timestamp()}"


class RealTimeFileMonitor:
    """Main file monitoring coordinator"""

    def __init__(self, config: dict):
        self.config = config
        self.watch_directories = config.get("watch_directories", [])
        self.processor_queue = asyncio.Queue(maxsize=config.get("queue_size", 1000))
        self.observers = []
        self.running = False
        self.stats = {
            "files_detected": 0,
            "files_queued": 0,
            "errors": 0,
            "start_time": None,
        }
        self.loop = asyncio.get_event_loop()

    async def start_monitoring(self):
        """Start monitoring all configured directories"""
        if self.running:
            return

        print("üöÄ Starting SpecStory file monitoring...")
        print(f"üìÅ Watching directories: {self.watch_directories}")

        self.stats["start_time"] = datetime.utcnow()
        self.running = True

        # Setup file watchers for each directory
        for directory in self.watch_directories:
            directory_path = Path(directory)
            if directory_path.exists():
                await self._setup_directory_watcher(directory_path)
            else:
                print(f"‚ö†Ô∏è Directory not found: {directory}")

        # Initial scan of existing files
        await self._initial_file_scan()

        print(f"‚úÖ File monitoring active on {len(self.observers)} directories")

        # Keep monitoring active
        try:
            while self.running:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            await self.stop_monitoring()

    async def _setup_directory_watcher(self, directory_path: Path):
        """Setup watchdog observer for a directory"""
        observer = Observer()
        handler = SpecStoryFileWatcher(
            self.processor_queue, self.config, loop=self.loop
        )
        observer.schedule(handler, str(directory_path), recursive=True)
        observer.start()
        self.observers.append(observer)
        print(f"üëÅÔ∏è Watching: {directory_path}")

    async def _initial_file_scan(self):
        """Scan existing files in watched directories"""
        print("üîç Scanning existing SpecStory files...")

        total_found = 0
        for directory in self.watch_directories:
            directory_path = Path(directory)
            if directory_path.exists():
                # Find all potential SpecStory files
                for pattern in ["**/*.md"]:
                    for filepath in directory_path.glob(pattern):
                        if filepath.is_file():
                            handler = SpecStoryFileWatcher(
                                self.processor_queue, self.config
                            )
                            if await handler._is_specstory_file(str(filepath)):
                                await handler._queue_for_processing(
                                    str(filepath), "existing"
                                )
                                total_found += 1

        print(f"üìö Found {total_found} existing SpecStory files")

    async def stop_monitoring(self):
        """Stop all file monitoring"""
        print("üõë Stopping file monitoring...")
        self.running = False

        for observer in self.observers:
            observer.stop()
            observer.join()

        self.observers.clear()
        print("‚úÖ File monitoring stopped")

    async def get_processing_queue(self) -> asyncio.Queue:
        """Get the processing queue for consumers"""
        return self.processor_queue

    def get_stats(self) -> dict:
        """Get monitoring statistics"""
        runtime = (
            (datetime.utcnow() - self.stats["start_time"]).total_seconds()
            if self.stats["start_time"]
            else 0
        )
        return {
            **self.stats,
            "runtime_seconds": runtime,
            "queue_size": self.processor_queue.qsize(),
            "directories_watched": len(self.observers),
        }


class MonitoringConfiguration:
    """Configuration management for file monitoring"""

    @staticmethod
    def load_config(config_path: str | None = None) -> dict:
        """Load monitoring configuration"""
        default_config = {
            "watch_directories": [
                "docs/",  # Watch the main documentation directory only
            ],
            "queue_size": 1000,
            "file_size_limit_mb": 100,
            "processing_timeout_seconds": 300,
            "monitoring_interval_seconds": 1,
            "max_concurrent_processing": 5,
        }

        if config_path and Path(config_path).exists():
            try:
                with open(config_path) as f:
                    user_config = json.load(f)
                default_config.update(user_config)
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading config from {config_path}: {e}")

        return default_config

    @staticmethod
    def save_config(config: dict, config_path: str):
        """Save configuration to file"""
        try:
            with open(config_path, "w") as f:
                json.dump(config, f, indent=2)
            print(f"üíæ Configuration saved to {config_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error saving config to {config_path}: {e}")


# Example usage and testing
async def main():
    """Example usage of the file monitoring system"""
    config = MonitoringConfiguration.load_config()

    # Create monitor
    monitor = RealTimeFileMonitor(config)

    # Start monitoring (this will run indefinitely)
    await monitor.start_monitoring()


if __name__ == "__main__":
    asyncio.run(main())
