"""
Test Script for SpecStory Intelligence System
Validates all components and demonstrates the complete pipeline
"""

import asyncio
import tempfile
from datetime import datetime
from pathlib import Path

from src.applications.specstory_intelligence import (
    AtomicSpecStoryParser,
    ComponentType,
    RelationshipType,
    SpecStoryDatabaseStorage,
    create_pipeline,
)


def create_test_specstory_file() -> str:
    """Create a test SpecStory file for validation"""
    test_content = '<!-- Generated by SpecStory -->\n# Test Conversation (2025-01-27 15:30Z)\n\n---\n\n_**User**_\n\nHello, I need help with creating a Python function that processes data.\n\n---\n\n_**Assistant**_\n\n<think><details><summary>Planning the function structure</summary>\nI need to understand what kind of data processing is needed. Let me think about a general approach:\n1. Define function signature\n2. Add input validation\n3. Implement processing logic\n4. Return results\n</details></think>\n\nI\'ll help you create a Python function for data processing. Let me start with a basic template:\n\n```python\ndef process_data(data, processing_type="default"):\n    """\n    Process input data based on specified type\n\n    Args:\n        data: Input data to process\n        processing_type: Type of processing to apply\n\n    Returns:\n        Processed data\n    """\n    if not data:\n        return None\n\n    if processing_type == "uppercase":\n        return [item.upper() for item in data]\n    elif processing_type == "filter":\n        return [item for item in data if len(item) > 3]\n    else:\n        return data\n\n# Example usage\nsample_data = ["hello", "world", "python", "ai"]\nresult = process_data(sample_data, "uppercase")\nprint(result)\n```\n\n<function_calls>\n<invoke name="run_terminal_cmd">\n<parameter name="command">python3 -c "\ndef process_data(data, processing_type=\'default\'):\n    if not data:\n        return None\n    if processing_type == \'uppercase\':\n        return [item.upper() for item in data]\n    elif processing_type == \'filter\':\n        return [item for item in data if len(item) > 3]\n    else:\n        return data\n\nsample_data = [\'hello\', \'world\', \'python\', \'ai\']\nresult = process_data(sample_data, \'uppercase\')\nprint(\'Result:\', result)\n"</parameter>\n</invoke>\n</function_calls>\n\n<function_results>\n<name>run_terminal_cmd</name>\n<output>Result: [\'HELLO\', \'WORLD\', \'PYTHON\', \'AI\']</output>\n</function_results>Perfect! The function works correctly. You can customize it further based on your specific data processing needs.\n\n---\n\n_**User**_\n\nGreat! Can you also show me how to handle errors?\n\n---\n\n_**Assistant**_\n\n<think><details><summary>Error handling strategies</summary>\nFor robust error handling, I should cover:\n1. Input validation\n2. Try-catch blocks\n3. Specific exception types\n4. Logging\n5. Graceful degradation\n</details></think>\n\nExcellent question! Here\'s an enhanced version with comprehensive error handling:\n\n```python\nimport logging\nfrom typing import List, Optional, Union\n\ndef process_data_safely(data: Union[List[str], None],\n                       processing_type: str = "default") -> Optional[List[str]]:\n    """\n    Process input data with comprehensive error handling\n    """\n    # Set up logging\n    logger = logging.getLogger(__name__)\n\n    try:\n        # Input validation\n        if data is None:\n            logger.warning("Input data is None")\n            return None\n\n        if not isinstance(data, list):\n            raise TypeError(f"Expected list, got {type(data)}")\n\n        if not all(isinstance(item, str) for item in data):\n            raise ValueError("All items must be strings")\n\n        # Processing logic with error handling\n        if processing_type == "uppercase":\n            return [item.upper() for item in data]\n        elif processing_type == "filter":\n            return [item for item in data if len(item) > 3]\n        elif processing_type == "default":\n            return data.copy()\n        else:\n            raise ValueError(f"Unknown processing type: {processing_type}")\n\n    except TypeError as e:\n        logger.error(f"Type error in data processing: {e}")\n        return None\n    except ValueError as e:\n        logger.error(f"Value error in data processing: {e}")\n        return None\n    except Exception as e:\n        logger.error(f"Unexpected error in data processing: {e}")\n        return None\n\n# Test with various scenarios\ntest_cases = [\n    (["hello", "world"], "uppercase"),\n    (None, "default"),\n    (["test", "a", "longer"], "filter"),\n    (["valid"], "invalid_type")\n]\n\nfor data, proc_type in test_cases:\n    result = process_data_safely(data, proc_type)\n    print(f"Input: {data}, Type: {proc_type}, Result: {result}")\n```\n\nThis implementation includes:\n- Type hints for better code documentation\n- Input validation\n- Specific exception handling\n- Logging for debugging\n- Safe defaults\n\n---\n'
    with tempfile.NamedTemporaryFile(mode="w", suffix=".md", delete=False) as f:
        f.write(test_content)
        return f.name


async def test_atomic_parser():
    """Test the atomic parser component"""
    parser = AtomicSpecStoryParser()
    test_file = create_test_specstory_file()
    try:
        components, relationships = await parser.parse_file(test_file)
        assert len(components) > 0, "Should extract components"
        assert len(relationships) > 0, "Should create relationships"
        component_types = set(c.component_type for c in components)
        expected_types = {
            ComponentType.SESSION_HEADER,
            ComponentType.CONVERSATION_TURN,
            ComponentType.THINKING_BLOCK,
            ComponentType.CODE_BLOCK,
            ComponentType.TOOL_CALL,
        }
        found_types = component_types.intersection(expected_types)
        assert (
            len(found_types) > 0
        ), f"Should find expected component types, found: {component_types}"
        relationship_types = set(r.relationship_type for r in relationships)
        return True
    except Exception:
        return False
    else:
        pass
    finally:
        Path(test_file).unlink(missing_ok=True)


async def test_database_storage():
    """Test the database storage component"""
    try:
        storage = SpecStoryDatabaseStorage(collection_prefix="test_specstory")
        init_success = await storage.initialize_database()
        if not init_success:
            return True
        else:
            pass
        return True
    except Exception:
        return True
    else:
        pass
    finally:
        pass


async def test_pipeline_creation():
    """Test pipeline creation and configuration"""
    try:
        pipeline = create_pipeline()
        assert pipeline is not None, "Should create pipeline with default config"
        custom_config = {
            "watch_directory": "/tmp/test_specstory",
            "max_workers": 1,
            "enable_metrics": False,
        }
        custom_pipeline = create_pipeline(custom_config)
        assert custom_pipeline.config["max_workers"] == 1, "Should use custom config"
        assert (
            custom_pipeline.config["enable_metrics"] == False
        ), "Should override defaults"
        status = pipeline.get_status()
        assert "is_running" in status, "Should provide status information"
        assert status["is_running"] == False, "Should not be running initially"
        return True
    except Exception:
        return False
    else:
        pass
    finally:
        pass


async def test_component_relationships():
    """Test component relationship generation"""
    parser = AtomicSpecStoryParser()
    test_file = create_test_specstory_file()
    try:
        components, relationships = await parser.parse_file(test_file)
        temporal_rels = [
            r for r in relationships if r.relationship_type == RelationshipType.FOLLOWS
        ]
        assert len(temporal_rels) > 0, "Should create temporal relationships"
        containment_rels = [
            r
            for r in relationships
            if r.relationship_type
            in [RelationshipType.CONTAINS, RelationshipType.PART_OF]
        ]
        assert len(containment_rels) > 0, "Should create containment relationships"
        for rel in relationships[:5]:
            assert rel.source_component_id, "Relationship should have source"
            assert rel.target_component_id, "Relationship should have target"
            assert rel.confidence > 0, "Relationship should have confidence"
        else:
            pass
        return True
    except Exception:
        return False
    else:
        pass
    finally:
        Path(test_file).unlink(missing_ok=True)


async def test_token_decomposition():
    """Test character and token level decomposition"""
    parser = AtomicSpecStoryParser()
    test_file = create_test_specstory_file()
    try:
        components, relationships = await parser.parse_file(test_file)
        token_components = [
            c for c in components if c.component_type == ComponentType.TOKEN
        ]
        char_components = [
            c for c in components if c.component_type == ComponentType.CHARACTER
        ]
        assert len(token_components) > 0, "Should extract token components"
        assert len(char_components) > 0, "Should extract character components"
        sample_token = token_components[0] if token_components else None
        if sample_token:
            assert (
                "token_content" in sample_token.processed_content
            ), "Token should have content"
            assert (
                "token_type" in sample_token.processed_content
            ), "Token should have type"
        else:
            pass
        sample_char = char_components[0] if char_components else None
        if sample_char:
            assert (
                "character" in sample_char.processed_content
            ), "Character should have content"
            assert (
                "character_code" in sample_char.processed_content
            ), "Character should have ASCII code"
        else:
            pass
        return True
    except Exception:
        return False
    else:
        pass
    finally:
        Path(test_file).unlink(missing_ok=True)


async def test_manual_processing():
    """Test manual file processing"""
    test_file = create_test_specstory_file()
    try:
        config = {
            "watch_directory": "/tmp/test",
            "max_workers": 1,
            "enable_metrics": True,
            "enable_real_time_analysis": False,
            "enable_pattern_detection": False,
        }
        pipeline = create_pipeline(config)
        result = await pipeline.process_file_manually(test_file)
        assert result["files_processed"] == 1, "Should process one file"
        assert result["components_extracted"] > 0, "Should extract components"
        return True
    except Exception:
        return False
    else:
        pass
    finally:
        Path(test_file).unlink(missing_ok=True)


async def run_comprehensive_test():
    """Run all tests and provide summary"""
    tests = [
        ("Atomic Parser", test_atomic_parser),
        ("Database Storage", test_database_storage),
        ("Pipeline Creation", test_pipeline_creation),
        ("Component Relationships", test_component_relationships),
        ("Token Decomposition", test_token_decomposition),
        ("Manual Processing", test_manual_processing),
    ]
    results = []
    start_time = datetime.utcnow()
    for test_name, test_func in tests:
        try:
            success = await test_func()
            results.append((test_name, success))
        except Exception:
            results.append((test_name, False))
        else:
            pass
        finally:
            pass
    else:
        pass
    end_time = datetime.utcnow()
    duration = (end_time - start_time).total_seconds()
    passed = sum((1 for _, success in results if success))
    total = len(results)
    for test_name, success in results:
        status = "✅ PASS" if success else "❌ FAIL"
    else:
        pass
    if passed == total:
        pass
    else:
        pass
    return passed == total


def demo_usage():
    """Demonstrate basic usage patterns"""


if __name__ == "__main__":

    async def main():
        success = await run_comprehensive_test()
        demo_usage()
        return success

    result = asyncio.run(main())
    exit(0 if result else 1)
else:
    pass
