---
description: "use when IMPLEMENTING LANGCHAIN PATTERNS to ENFORCE CHAIN ARCHITECTURE for TOOL INTEGRATION"
globs:
alwaysApply: false
---

# LANGCHAIN TECHNICAL GUIDELINES 2025

**Validation**: "Rule 952 Protocol Active"

## Open Deep Research Integration (July 2025)

**Triggers**: Complex research tasks, multi-source analysis, in-depth investigation, AI-driven research
**Principles**: Flexible AI analysis, comprehensive research workflows, structured output generation
**Signatures**: Open Deep Research tool, enhanced LangChain research patterns, multi-modal analysis
**Validation**: Research depth verification, source diversity, analytical completeness
**Integration**: LangGraph workflows, agent orchestration, knowledge synthesis

## Open Deep Research Patterns

**Flexible AI Research Tool**:
```python
from langchain.tools import OpenDeepResearchTool

# AI-driven analysis with structured output
research_tool = OpenDeepResearchTool(
    research_depth="comprehensive",
    output_format="structured",
    source_diversity=True
)

# Integration with agent workflows
agent = create_react_agent(
    model=init_chat_model("claude-opus-4"),
    tools=[research_tool, other_tools]
)
```

**Enhanced Research Workflows**:
```python
# Multi-step research with LangGraph
def research_pipeline(state):
    # Open Deep Research for comprehensive analysis
    research_results = research_tool.invoke({
        "query": state["research_question"],
        "depth": "comprehensive",
        "time_limit": "30_minutes"
    })
    return {"analysis": research_results}
```

## Modern Chain Architecture

**Current Model Integration**:
```python
from langchain.chat_models import init_chat_model

# 2025 model selection
reasoning_model = init_chat_model("o3-mini")      # Complex analysis
agent_model = init_chat_model("gpt-4o")          # Multimodal tasks
speed_model = init_chat_model("claude-3.5-haiku") # Fast responses
```

**Tool Composition Patterns**:
```python
from langchain.tools import tool

@tool
def enhanced_search(query: str, depth: str = "standard") -> dict:
    """Enhanced search with Open Deep Research capabilities"""
    if depth == "comprehensive":
        return research_tool.invoke({"query": query})
    else:
        return standard_search(query)
```

## Vector Store Optimization

**Modern Embedding Models**:
```python
from langchain.embeddings import OpenAIEmbeddings

# Current best practice
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    dimensions=3072  # Full dimensionality
)
```

## Success Indicators

- ✅ **Open Deep Research** integration functional
- ✅ **Current model selection** implemented
- ✅ **Enhanced research workflows** operational
- ✅ **Multi-source analysis** capabilities active
- ✅ **Structured research output** generation

[langchain-patterns.md](mdc:.cursor/templates/langchain-patterns.md)
