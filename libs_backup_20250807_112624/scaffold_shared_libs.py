#!/usr/bin/env python3
"""
scaffold_shared_libs.py

A production-ready utility that helps teams enforce DRY (Don't Repeat Yourself)
principles inside a mono-repo that hosts multiple Python libraries.

Main capabilities
-----------------
1. Duplicate analysis
   â€¢ Detects identical Python files across all packages in ./libs
   â€¢ Prints a human-readable report or emits JSON for automation

2. Library scaffolding
   â€¢ Generates a modern, PEP-compliant project skeleton (PEP 621 metadata)
   â€¢ Inserts only *one* copy of common code (via symlinks or, as a fallback,
     physical copies when the OS denies symlink creation)
   â€¢ Works entirely with the Python standard libraryâ€”no bootstrap deps

Usage
-----
$ python scaffold_shared_libs.py analyse
$ python scaffold_shared_libs.py analyse --json > dupes.json
$ python scaffold_shared_libs.py scaffold my-new-lib
$ python scaffold_shared_libs.py scaffold my-new-lib --force   # overwrite

The script is idempotent and safe to run repeatedly (use --force when you
explicitly want to clobber an existing library scaffold).

Author
------
Senior Python Developer â€“ OPSVI
"""

from __future__ import annotations

import argparse
import hashlib
import json
import logging
import os
import shutil
import sys
import textwrap
from pathlib import Path
from string import Template
from typing import Dict, List, Mapping, MutableMapping

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
LOG_FORMAT = "%(asctime)s | %(levelname)-8s | %(name)s:%(lineno)d â€“ %(message)s"
logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)
logger = logging.getLogger("scaffold")

# -----------------------------------------------------------------------------
# Constants
# -----------------------------------------------------------------------------
LIBS_DIR: Path = Path("libs").resolve()

# -----------------------------------------------------------------------------
# Embedded templates
# -----------------------------------------------------------------------------
_PYPROJECT_TOML = Template(
    textwrap.dedent(
        """\
        [project]
        name = "$package_name"
        version = "0.0.1"
        description = "TODO: describe $package_name"
        authors = [
            { name = "OPSVI", email = "opsvi@example.com" }
        ]
        readme = "README.md"
        requires-python = ">=3.9"
        license = { text = "MIT" }
        classifiers = [
            "Programming Language :: Python :: 3",
            "License :: OSI Approved :: MIT License",
            "Operating System :: OS Independent",
        ]

        [tool.black]
        target-version = ["py39"]

        [tool.ruff]
        line-length = 88

        [tool.mypy]
        strict = true
        """
    )
)

_INIT_PY = Template(
    textwrap.dedent(
        '''\
        """
        $package_name
        -------------
        A DRY-compliant shared library scaffolded by scaffold_shared_libs.py.
        """
        from __future__ import annotations

        __all__: list[str] = []
        __version__ = "0.0.1"
        '''
    )
)

_README_MD = Template(
    textwrap.dedent(
        """\
        # $package_name

        **Status**: alpha

        Scaffolding generated by `scaffold_shared_libs.py`.
        Replace this file with real project documentation.
        """
    )
)

# -----------------------------------------------------------------------------
# Helper utilities
# -----------------------------------------------------------------------------


def sha256_of_file(path: Path, *, chunk_size: int = 1 << 16) -> str:
    """Return SHA-256 hexdigest of *path*, streaming to avoid RAM blow-ups."""
    digest = hashlib.sha256()
    with path.open("rb") as fh:
        for chunk in iter(lambda: fh.read(chunk_size), b""):
            digest.update(chunk)
    return digest.hexdigest()


def collect_python_files(directory: Path) -> List[Path]:
    """Recursively return every *.py file below *directory*."""
    return [p for p in directory.rglob("*.py") if p.is_file()]


# -----------------------------------------------------------------------------
# Duplicate-analysis logic
# -----------------------------------------------------------------------------


def analyse_duplicates(base: Path = LIBS_DIR) -> Dict[str, List[Path]]:
    """
    Compute SHA-256 digests for all Python files under *base*.

    Returns:
        A mapping {digest: [files]} containing only entries that occur
        in two or more locations (i.e. actual duplication).
    """
    logger.debug("Analysing duplicate files under %s", base)

    digest_map: MutableMapping[str, List[Path]] = {}

    for py_file in collect_python_files(base):
        digest = sha256_of_file(py_file)
        digest_map.setdefault(digest, []).append(py_file)

    duplicates = {d: ps for d, ps in digest_map.items() if len(ps) > 1}
    logger.info("Duplicate scan complete â€“ %d duplicated blobs found", len(duplicates))
    return duplicates


def print_duplicate_report(dupes: Mapping[str, List[Path]]) -> None:
    """Pretty-print a duplication report for human consumption."""
    if not dupes:
        print("âœ…  No duplicated Python files detected.")
        return

    print("ðŸš¨  Duplicate Python files detected:\n")
    for idx, (digest, paths) in enumerate(dupes.items(), 1):
        print(f"{idx:02d}. {len(paths)}Ã— â€“ SHA-256 {digest[:12]}â€¦")
        for p in paths:
            try:
                rel = p.relative_to(LIBS_DIR.parent)
            except ValueError:
                rel = p
            print(f"    â€¢ {rel}")
    print(
        "\nHint: Extract shared functionality into a common package and import "
        "it instead of duplicating code."
    )


# -----------------------------------------------------------------------------
# Scaffolding helpers
# -----------------------------------------------------------------------------


def _render(template: Template, **ctx: str) -> str:
    return template.substitute(**ctx)


def _link_or_copy(
    target: Path,
    source: Path,
    *,
    force: bool = False,
) -> None:
    """
    Try to create a symlink at *target* pointing to *source*.  On platforms
    or configurations where symlinks require elevated privileges (e.g. Windows
    without Developer Mode), fall back to copying the file/directory.

    Args:
        target: Destination path to create.
        source: Existing path that should be referenced.
        force:  Overwrite *target* if it already exists.
    """
    if target.exists():
        if not force:
            raise FileExistsError(f"{target} already exists")
        if target.is_symlink() or target.is_file():
            target.unlink()
        else:
            shutil.rmtree(target)

    target.parent.mkdir(parents=True, exist_ok=True)

    try:
        target.symlink_to(source, target_is_directory=source.is_dir())
        logger.debug("Symlink created %s â†’ %s", target, source)
    except (OSError, NotImplementedError) as exc:
        # Fall back to copying
        logger.debug(
            "Symlink failed (%s). Falling back to copying %s â†’ %s", exc, source, target
        )
        # Remove any half-created symlink
        target.unlink(missing_ok=True)
        if source.is_dir():
            shutil.copytree(source, target, dirs_exist_ok=force)
        else:
            shutil.copy2(source, target)


def _write_file(path: Path, content: str) -> None:
    """Write *content* to *path* using UTF-8 encoding."""
    path.write_text(content, encoding="utf-8")


# -----------------------------------------------------------------------------
# Scaffold logic
# -----------------------------------------------------------------------------


def scaffold_library(
    name: str,
    *,
    base: Path = LIBS_DIR,
    force: bool = False,
) -> Path:
    """
    Generate a DRY-compliant library skeleton inside *base*.

    Structure:
        libs/<name>/
            pyproject.toml
            README.md
            <package_name>/__init__.py
            <package_name>/logging.py  (symlink or copy to central file)

    Returns:
        Path to the newly created library root.
    """
    package_name = name.replace("-", "_")
    lib_root = base / name
    package_root = lib_root / package_name

    if lib_root.exists():
        if not force:
            raise FileExistsError(
                f"{lib_root} already exists â€“ pass --force to overwrite"
            )
        shutil.rmtree(lib_root)

    logger.info("Creating library scaffold at %s", lib_root)
    package_root.mkdir(parents=True, exist_ok=True)

    # Write template files
    _write_file(lib_root / "pyproject.toml", _render(_PYPROJECT_TOML, package_name=package_name))
    _write_file(lib_root / "README.md", _render(_README_MD, package_name=package_name))
    _write_file(package_root / "__init__.py", _render(_INIT_PY, package_name=package_name))

    # DRY example: centralise logging setup
    foundation_logging = (
        base / "opsvi-foundation" / "opsvi_foundation" / "observability" / "logging.py"
    ).resolve()

    if foundation_logging.exists():
        _link_or_copy(package_root / "logging.py", foundation_logging, force=force)
        logger.info(
            "Centralised observability â€¢ linked logging.py to %s",
            foundation_logging.relative_to(base.parent),
        )
    else:
        logger.warning(
            "Central logging implementation not found at %s â€“ skipping symlink/copy",
            foundation_logging,
        )

    logger.info("âœ…  Scaffold for '%s' created successfully", package_name)
    return lib_root


# -----------------------------------------------------------------------------
# CLI
# -----------------------------------------------------------------------------


def _build_cli() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="scaffold_shared_libs",
        description=(
            "Analyse ./libs for duplicate code and scaffold new DRY-compliant libraries."
        ),
    )
    sub = parser.add_subparsers(dest="command", required=True)

    # analyse sub-command
    analyse_cmd = sub.add_parser("analyse", help="Detect duplicate Python files")
    analyse_cmd.add_argument(
        "--json",
        action="store_true",
        help="Emit results as JSON instead of human text",
    )

    # scaffold sub-command
    scaffold_cmd = sub.add_parser("scaffold", help="Generate a new library skeleton")
    scaffold_cmd.add_argument("name", help="Name of the library (e.g. opsvi-utils)")
    scaffold_cmd.add_argument(
        "--force",
        action="store_true",
        help="Overwrite any existing directory",
    )

    return parser


def _cmd_analyse(args: argparse.Namespace) -> None:
    duplicates = analyse_duplicates()
    if args.json:
        json.dump(
            {digest: [str(p) for p in files] for digest, files in duplicates.items()},
            sys.stdout,
            indent=2,
        )
        sys.stdout.write("\n")
    else:
        print_duplicate_report(duplicates)


def _cmd_scaffold(args: argparse.Namespace) -> None:
    try:
        scaffold_library(args.name, force=args.force)
    except FileExistsError as exc:
        logger.error("%s", exc)
        sys.exit(1)


# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------


def main(argv: List[str] | None = None) -> None:
    parser = _build_cli()
    args = parser.parse_args(argv)

    if args.command == "analyse":
        _cmd_analyse(args)
    elif args.command == "scaffold":
        _cmd_scaffold(args)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.warning("Interrupted by user")
        sys.exit(130)
