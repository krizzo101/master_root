# SDLC Orchestrator Configuration
# Customize execution behavior, timeouts, and tool selection

orchestrator:
  # Maximum parallel executions
  max_parallel: 3

  # Default timeout for tasks (seconds)
  default_timeout: 300

  # Enable automatic retry on failure
  auto_retry: true

  # Enable continuous validation after each wave
  continuous_validation: true

  # Session export settings
  session_export:
    enabled: true
    directory: ".sdlc-sessions"
    format: "json"  # json, yaml, or csv
    compress: false  # Compress large session files

  # Cost management
  cost_limits:
    per_task_usd: 0.10
    per_phase_usd: 1.00
    per_project_usd: 10.00

# Execution mode selection criteria
mode_selection:
  # Use Task tool for these operations
  task_tool:
    operations:
      - file_writer
      - file_reader
      - directory_creator
      - grep
      - glob
      - ls
      - edit
      - multi_edit
    max_duration: 300  # 5 minutes max

  # Use MCP server for these operations
  mcp_server:
    operations:
      - code_editor
      - database_tool
      - api_tester
      - test_runner
      - deployment_tool
      - system_command
      - package_manager
    min_duration: 180  # Use for tasks > 3 minutes

  # Prefer Task tool for these file patterns
  task_tool_patterns:
    - "*.md"
    - "*.txt"
    - "*.json"
    - "*.yaml"
    - "*.yml"
    - "README*"
    - "LICENSE*"

  # Prefer MCP for these file patterns
  mcp_patterns:
    - "*.py"
    - "*.js"
    - "*.ts"
    - "*.java"
    - "*.go"
    - "*.rs"
    - "test_*.py"
    - "*_test.py"

# Agent type mapping
agent_types:
  research: "research-specialist"
  testing: "test-specialist"
  documentation: "documentation-specialist"
  refactoring: "refactoring-master"
  deployment: "deployment-specialist"
  security: "security-specialist"
  performance: "performance-specialist"
  default: "general-purpose"

# Validation settings
validation:
  # Required file patterns for each phase
  phase_requirements:
    discovery:
      required_files:
        - "requirements.md"
        - "user_stories.md"
      required_sections:
        - "Functional Requirements"
        - "Non-Functional Requirements"
        - "Constraints"

    design:
      required_files:
        - "design.md"
        - "architecture.md"
      required_sections:
        - "System Architecture"
        - "Component Design"
        - "Data Model"

    development:
      required_patterns:
        - "src/*.py"
        - "tests/*.py"
      min_test_coverage: 0.7

    deployment:
      required_files:
        - "Dockerfile"
        - "docker-compose.yml"
        - "deployment.md"

  # Error patterns to detect
  error_patterns:
    - "error:"
    - "exception:"
    - "failed:"
    - "traceback"
    - "syntaxerror"
    - "nameerror"
    - "typeerror"
    - "valueerror"
    - "importerror"
    - "modulenotfounderror"
    - "timeout"
    - "killed"

# Retry configuration
retry:
  # Maximum retry attempts
  max_attempts: 3

  # Backoff strategy
  backoff_strategy: "exponential"  # linear, exponential, or fixed
  backoff_base: 2  # For exponential: timeout * (base ^ attempt)

  # Retry on these error patterns
  retry_on:
    - "timeout"
    - "connection"
    - "rate limit"
    - "temporary"

  # Don't retry on these error patterns
  no_retry_on:
    - "syntax"
    - "import"
    - "permission"
    - "not found"

# Performance optimization
performance:
  # Cache task outputs for reuse
  enable_cache: true
  cache_ttl: 3600  # Cache TTL in seconds

  # Batch similar tasks
  batch_similar: true
  batch_size: 5

  # Predictive scaling
  predictive_scaling: false
  scale_threshold: 0.8  # CPU/memory threshold

# Monitoring and alerts
monitoring:
  # Enable real-time monitoring
  enabled: true

  # Metrics to track
  metrics:
    - execution_time
    - success_rate
    - cost
    - token_usage
    - parallel_efficiency

  # Alert thresholds
  alerts:
    task_timeout_seconds: 600
    phase_timeout_minutes: 30
    cost_per_task_usd: 0.20
    failure_rate_percent: 20

  # Export metrics
  export:
    enabled: true
    format: "prometheus"  # prometheus, datadog, or json
    endpoint: "http://localhost:9090/metrics"

# Integration settings
integrations:
  # Task tool integration
  task_tool:
    enabled: true
    endpoint: "local"  # local, api, or custom
    api_key: "${TASK_TOOL_API_KEY}"
    timeout: 30

  # MCP server integration
  mcp_server:
    enabled: true
    endpoint: "local"  # local, api, or custom
    api_key: "${MCP_API_KEY}"
    timeout: 60

  # External services
  services:
    github:
      enabled: false
      token: "${GITHUB_TOKEN}"

    slack:
      enabled: false
      webhook: "${SLACK_WEBHOOK}"

    datadog:
      enabled: false
      api_key: "${DATADOG_API_KEY}"

# Logging configuration
logging:
  # Log level
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR

  # Log destinations
  destinations:
    - console
    - file

  # File logging
  file:
    path: ".sdlc-logs/orchestrator.log"
    max_size_mb: 100
    max_backups: 5

  # Structured logging
  format: "json"  # json or text

  # Include these in logs
  include:
    - timestamp
    - task_id
    - session_id
    - duration
    - status
    - error
