"""
Agent Response Models for Structured Output Enforcement

Defines the exact schema that ALL agents must use for their responses.
This eliminates format detection and ensures predictable parsing.
"""

# Import StrictBaseModel for OpenAI compatibility
import sys
from pathlib import Path
from typing import Any

from pydantic import Field

sys.path.append(str(Path(__file__).parent.parent))
from pydantic_configs import StrictBaseModel


class GeneratedFile(StrictBaseModel):
    """Single file generated by an agent - MANDATORY FORMAT"""

    filename: str = Field(
        ...,
        description="Complete file path with directory (e.g., 'src/main.py', 'docs/README.md')",
    )
    content: str = Field(
        ..., description="Complete file content - must be ready to write directly"
    )
    file_type: str = Field(
        ..., description="File type: code, documentation, configuration, test, etc."
    )
    description: str = Field(
        ..., description="Brief description of what this file does"
    )


class ToolExecution(StrictBaseModel):
    """Tool execution performed by agent"""

    tool_name: str = Field(..., description="Name of the tool used")
    parameters: dict[str, Any] = Field(..., description="Parameters passed to tool")
    result_summary: str = Field(..., description="Summary of tool execution result")
    success: bool = Field(..., description="Whether tool execution succeeded")


class AgentDeliverables(StrictBaseModel):
    """MANDATORY structured response format for ALL agents"""

    # Core deliverables
    generated_files: list[GeneratedFile] = Field(
        ...,
        description="All files created by this agent (MUST be non-empty for successful completion)",
    )

    # Execution summary
    task_summary: str = Field(
        ..., description="Clear summary of what the agent accomplished"
    )

    success_status: bool = Field(
        ..., description="True if agent completed its assigned task successfully"
    )

    # Optional additional information
    tools_used: list[ToolExecution] = Field(
        default_factory=list, description="Tools executed during task completion"
    )

    reasoning_chain: list[str] = Field(
        default_factory=list, description="Step-by-step reasoning for task completion"
    )

    validation_results: list[str] = Field(
        default_factory=list, description="Self-validation checks performed"
    )

    additional_notes: str | None = Field(
        None, description="Any additional notes or recommendations"
    )


class AgentResponse(StrictBaseModel):
    """Complete agent response wrapper - TOP LEVEL SCHEMA"""

    agent_id: str = Field(..., description="Agent identifier")
    agent_role: str = Field(..., description="Agent role description")
    request_processed: str = Field(..., description="Summary of request processed")

    # The main deliverables
    deliverables: AgentDeliverables = Field(
        ..., description="Structured deliverables from agent execution"
    )

    # Metadata
    execution_time_seconds: float | None = Field(
        None, description="Time taken to complete task"
    )

    confidence_score: float = Field(
        default=0.9, ge=0.0, le=1.0, description="Confidence in task completion (0-1)"
    )
