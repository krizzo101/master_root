"""
Workflow Models for Smart Decomposition Agent

Data models, enums, and validation functions for O3-driven workflow specifications.
Extracted from smart_decomposition_agent.py for better modularity.
"""

# Import StrictBaseModel for OpenAI compatibility
import sys
from enum import Enum
from pathlib import Path
from typing import Annotated, Any, TypedDict

from pydantic import BaseModel, Field

sys.path.append(str(Path(__file__).parent.parent))
from pydantic_configs import StrictBaseModel


class ExecutionMode(str, Enum):
    """Execution modes for workflow components"""

    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    CONDITIONAL = "conditional"
    DYNAMIC = "dynamic"


class AgentModel(str, Enum):
    """Available models for agent execution - only o3-mini reasoning and gpt-4.1-mini agent models"""

    REASONING = "o3-mini"  # O3-mini reasoning model for complex meta-intelligence
    AGENT = "gpt-4.1-mini"  # GPT-4.1-mini agent model for specialized tasks


class ToolSpecification(StrictBaseModel):
    """Complete tool specification generated by O3"""

    tool_name: str = Field(description="Exact MCP tool name")
    # NO FALLBACKS RULE: Tool parameters must be explicitly provided
    parameters: dict[str, str] = Field(description="Tool configuration parameters")
    usage_context: str = Field(description="When and how this tool should be used")
    expected_outputs: list[str] = Field(description="Expected tool outputs and formats")


class FileDeliverable(StrictBaseModel):
    """Specific file that must be generated"""

    filename: str = Field(description="Exact filename with extension")
    file_type: str = Field(description="File type (code, documentation, config, etc.)")
    content_requirements: str = Field(description="Detailed content requirements")
    validation_criteria: list[str] = Field(
        description="Criteria for validating file quality"
    )


class AgentSpecification(StrictBaseModel):
    """Complete agent specification generated by O3"""

    agent_id: str = Field(
        description="Unique filesystem-safe identifier (no spaces, special chars)"
    )
    role: str = Field(description="Agent role description")
    model: AgentModel = Field(description="Model to use for this agent")
    complete_prompt: str = Field(
        description="Complete executable prompt for this agent"
    )
    tools: list[ToolSpecification] = Field(description="Tools this agent can use")
    required_deliverables: list[FileDeliverable] = Field(
        description="Files this agent must create"
    )
    success_criteria: list[str] = Field(
        description="Criteria for successful completion"
    )
    # NO FALLBACKS RULE: Max iterations must be explicitly provided
    max_iterations: int = Field(description="Maximum execution attempts")
    # NO FALLBACKS RULE: Subagent creation capability must be explicitly specified
    can_create_subagents: bool = Field(
        description="Can this agent create sub-workflows"
    )
    # NO FALLBACKS RULE: O3 calling capability must be explicitly specified
    can_call_o3: bool = Field(description="Can this agent request O3 planning")


class RoutingCondition(StrictBaseModel):
    """Conditional logic for workflow routing"""

    condition_type: str = Field(
        description="Type of condition (success, failure, output_contains, etc.)"
    )
    condition_value: str = Field(description="Value to check against")
    next_agent: str = Field(description="Agent ID to route to if condition is met")
    # NO FALLBACKS RULE: State updates must be explicitly provided
    state_updates: dict[str, str] = Field(description="State updates to apply")


class WorkflowNode(StrictBaseModel):
    """Individual workflow execution node"""

    node_id: str = Field(description="Unique node identifier")
    agent_id: str = Field(description="Agent to execute at this node")
    execution_mode: ExecutionMode = Field(description="How this node executes")
    routing_conditions: list[RoutingCondition] = Field(
        description="Conditions for routing after execution"
    )
    # NO FALLBACKS RULE: Parallel nodes must be explicitly provided
    parallel_nodes: list[str] = Field(description="Nodes that can execute in parallel")
    required_inputs: list[str] = Field(
        description="Required state inputs for this node"
    )
    output_mappings: dict[str, str] = Field(description="How to map outputs to state")


class StateManagement(StrictBaseModel):
    """Complete state management specification"""

    initial_state: dict[str, str] = Field(description="Initial workflow state")
    state_schema: dict[str, str] = Field(
        description="Expected state structure and types"
    )
    persistence_rules: list[str] = Field(description="How state should be persisted")
    validation_rules: list[str] = Field(description="State validation requirements")


class ErrorHandling(StrictBaseModel):
    """Error handling strategy generated by O3"""

    error_type: str = Field(description="Type of error this handles")
    recovery_strategy: str = Field(description="How to recover from this error")
    fallback_agent: str | None = Field(description="Agent to fallback to if any")
    max_retries: int = Field(description="Maximum retry attempts")
    escalation_conditions: list[str] = Field(description="When to escalate to O3")


class WorkflowSpecification(StrictBaseModel):
    """Complete workflow architecture generated by O3"""

    workflow_id: str = Field(description="Unique workflow identifier")
    workflow_description: str = Field(description="High-level workflow description")
    agents: list[AgentSpecification] = Field(description="All agents in this workflow")
    execution_graph: list[WorkflowNode] = Field(description="Complete execution flow")
    state_management: StateManagement = Field(
        description="State management configuration"
    )
    success_criteria: list[str] = Field(description="Overall workflow success criteria")
    deliverables: list[FileDeliverable] = Field(
        description="Final deliverables expected"
    )
    error_handling: list[ErrorHandling] = Field(description="Error handling strategies")
    estimated_duration: str = Field(description="Estimated execution time")
    performance_requirements: list[str] = Field(
        description="Performance optimization requirements"
    )


class ReasoningAnalysis(StrictBaseModel):
    """Complete meta-intelligence analysis from O3 reasoning model"""

    request_analysis: str = Field(description="Deep analysis of the user request")
    complexity_assessment: int = Field(
        ge=1, le=100, description="Complexity score 1-100"
    )
    approach_rationale: str = Field(description="Why this approach was chosen")
    workflow_specification: WorkflowSpecification = Field(
        description="Complete workflow architecture"
    )
    adaptive_capabilities: list[str] = Field(
        description="How workflow can adapt during execution"
    )
    resource_requirements: dict[str, str] = Field(
        description="Computational and time requirements"
    )
    risk_assessment: list[str] = Field(
        description="Potential risks and mitigation strategies"
    )


# ================================
# AVAILABLE MCP TOOLS CATALOG
# Framework capabilities that O3 can assign to agents
# ================================

AVAILABLE_MCP_TOOLS = {
    # Code Operations
    "codebase_search": "Semantic search for understanding code by meaning",
    "read_file": "Read file contents with line range support",
    "edit_file": "Create or edit files with structured changes",
    "search_replace": "Precise search and replace in files",
    "grep_search": "Fast exact text/regex searches",
    "file_search": "Fuzzy file path searching",
    "list_dir": "Directory content listing",
    "delete_file": "File deletion",
    # System Operations
    "run_terminal_cmd": "Execute terminal commands",
    "mcp_shell_shell_exec": "Enhanced shell command execution",
    # Research & Web
    "web_search": "Web search for current information",
    "mcp_web_scraping_firecrawl_scrape": "Advanced web content extraction",
    "mcp_web_scraping_firecrawl_search": "Web search with content extraction",
    "mcp_tech_docs_resolve_library_id": "Resolve library documentation IDs",
    "mcp_tech_docs_get_library_docs": "Fetch technical documentation",
    "mcp_research_papers_search_papers": "Search academic papers on arXiv",
    "mcp_research_papers_download_paper": "Download and process research papers",
    # Intelligence & Analysis
    "mcp_thinking_sequentialthinking": "Advanced reasoning and problem-solving",
    "create_diagram": "Generate Mermaid diagrams with accessibility standards",
    "update_memory": "Persistent knowledge base management",
}

# ================================
# FRAMEWORK GUARDRAILS & VALIDATION
# Safety constraints for O3 specifications
# ================================


def validate_agent_specification(agent_spec: AgentSpecification) -> list[str]:
    """Validate that O3's agent specification is safe and executable"""
    errors = []

    # Filesystem safety
    if not agent_spec.agent_id.replace("_", "").replace("-", "").isalnum():
        errors.append(f"Agent ID '{agent_spec.agent_id}' contains invalid characters")

    # Tool validation
    for tool in agent_spec.tools:
        if tool.tool_name not in AVAILABLE_MCP_TOOLS:
            errors.append(f"Unknown tool: {tool.tool_name}")

    # Required fields
    if not agent_spec.complete_prompt.strip():
        errors.append("Agent must have complete_prompt")

    if not agent_spec.required_deliverables:
        errors.append("Agent must specify required_deliverables")

    return errors


def validate_workflow_specification(workflow_spec: WorkflowSpecification) -> list[str]:
    """Validate that O3's workflow specification is executable"""
    errors = []

    # Agent validation
    agent_ids = {agent.agent_id for agent in workflow_spec.agents}

    # Check execution graph references valid agents
    for node in workflow_spec.execution_graph:
        if node.agent_id not in agent_ids:
            errors.append(
                f"Node {node.node_id} references unknown agent: {node.agent_id}"
            )

    # Check for unreachable agents
    referenced_agents = {node.agent_id for node in workflow_spec.execution_graph}
    unreferenced = agent_ids - referenced_agents
    if unreferenced:
        errors.append(f"Unreferenced agents: {unreferenced}")

    return errors


# State Reducers for LangGraph Concurrent Updates
def merge_agent_outputs(
    existing: dict[str, Any], new: dict[str, Any]
) -> dict[str, Any]:
    """Merge agent outputs from multiple parallel agents"""
    if existing is None:
        existing = {}
    if new is None:
        return existing
    # Merge the dictionaries - each agent updates a different key
    merged = existing.copy()
    merged.update(new)
    return merged


def merge_context(existing: dict[str, Any], new: dict[str, Any]) -> dict[str, Any]:
    """Merge context updates from multiple agents"""
    if existing is None:
        existing = {}
    if new is None:
        return existing
    merged = existing.copy()
    merged.update(new)
    return merged


def merge_errors(existing: list[str], new: list[str]) -> list[str]:
    """Merge error lists from multiple agents"""
    if existing is None:
        existing = []
    if new is None:
        return existing
    return existing + new


# State Management - TypedDict with Annotated reducers for LangGraph
class SmartDecompositionState(TypedDict):
    """State for Smart Decomposition workflow - TypedDict for LangGraph compatibility"""

    user_request: str
    project_name: str | None
    project_path: str | None
    complexity_analysis: dict[str, Any] | None
    workflow_plan: dict[str, Any] | None
    specialized_agents: dict[str, Any] | None  # Dict for Send API
    agent_outputs: Annotated[
        dict[str, Any], merge_agent_outputs
    ]  # Reducer for parallel updates
    final_solution: dict[str, Any] | None
    context: Annotated[dict[str, Any], merge_context]  # Reducer for context updates
    errors: Annotated[list[str], merge_errors]  # Reducer for error aggregation
    # Dynamic pipeline fields
    pipeline_design: dict[str, Any] | None
    pipeline_results: dict[str, Any] | None
    workflow_specification: dict[str, Any] | None
    # Send API support
    current_agent_role: str | None  # Track current agent for Send API


# Request Analysis Models
class ComplexityAnalysis(BaseModel):
    """O3 reasoning output for request complexity analysis"""

    complexity_score: int = Field(description="0-100 complexity rating")
    required_capabilities: list[str] = Field(
        description="List of required capabilities"
    )
    recommended_agents: list[str] = Field(description="Recommended specialist agents")
    execution_strategy: str = Field(description="Sequential or parallel execution")
    estimated_steps: int = Field(description="Number of workflow steps")


class SolutionOutput(BaseModel):
    """Final solution output"""

    artifacts: list[dict[str, Any]] = Field(description="Generated files and outputs")
    execution_summary: str = Field(description="Summary of execution process")
    performance_metrics: dict[str, Any] = Field(description="Performance statistics")
    quality_assessment: dict[str, Any] = Field(description="Quality metrics")
