"""
Execution Engine Module

ðŸ”’ **CRITICAL WARNING - DO NOT MODIFY SEND API IMPLEMENTATION** ðŸ”’

This module implements LangGraph StateGraph with Send API for proper agent orchestration.
The implementation has been modified multiple times and MUST NOT BE REVERTED.

ðŸš¨ **MANDATORY PATTERNS - VIOLATION WILL BREAK THE SYSTEM:**

1. **STATE HANDLING**: LangGraph converts TypedDict to plain dict during execution
   - NEVER access state.attribute_name
   - ALWAYS use state.get("attribute_name", default)
   - Return types must be dict, not SmartDecompositionState

2. **SEND API PATTERNS**: Must use Send objects for parallel execution
   - NEVER use asyncio.gather - FORBIDDEN by project rules
   - ALWAYS use Send API for agent coordination
   - Separate node functions from routing functions

3. **LANGGRAPH ARCHITECTURE**: Must follow documented patterns
   - Node functions: Return state updates
   - Routing functions: Return Send objects
   - Use add_conditional_edges for Send routing

âŒ **PROHIBITED PATTERNS THAT WILL BE REVERTED:**
   - asyncio.gather usage (Rule 997 violation)
   - Manual state routing without Send API
   - TypedDict access patterns in StateGraph nodes
   - Sequential execution instead of parallel Send API

âœ… **REQUIRED PATTERNS THAT MUST BE MAINTAINED:**
   - from langgraph.constants import Send
   - add_conditional_edges with Send objects
   - State accessed as dict with .get() methods
   - Separate _prepare and _create_send_objects functions

ðŸ” **RULE ENFORCEMENT:**
   - Rule 950: LangGraph Technical Guidelines (Send API mandatory)
   - Rule 956: AI Development 2025 (LangGraph-first approach)
   - Rule 997: Immediate Violation Blocker (asyncio.gather forbidden)

This implementation provides 3-5x performance improvement over sequential execution
and is the ONLY approved pattern for OAMAT-SD agent orchestration.

LAST MODIFIED: 2025-07-19 - LangGraph StateGraph with Send API implementation
MAINTAINER: OAMAT-SD Team - DO NOT REVERT WITHOUT ARCHITECTURAL REVIEW
"""

from datetime import datetime

from langchain_core.messages import HumanMessage

# ðŸ”’ CRITICAL: Send API import - DO NOT REMOVE
# ðŸ”’ **CRITICAL IMPORTS - DO NOT REMOVE** - Rules 950/956/999 ðŸ”’
# âš ï¸  Send API import MANDATORY for parallel execution
# âš ï¸  Removing Send breaks entire orchestration system
# âš ï¸  StateGraph imports required for LangGraph compliance
from langgraph.constants import Send  # ðŸ”’ REQUIRED for parallel agent coordination
from langgraph.graph import END, START, StateGraph

from src.applications.oamat_sd.src.models.workflow_models import SmartDecompositionState
from src.applications.oamat_sd.src.sd_logging import LoggerFactory


class ExecutionEngine:
    """
    ðŸ”’ **CRITICAL: LangGraph StateGraph-based parallel execution - DO NOT MODIFY** ðŸ”’

    This class implements the ONLY approved pattern for OAMAT-SD agent orchestration:
    - LangGraph StateGraph for workflow management
    - Send API for parallel agent coordination
    - Native LangGraph patterns (NO custom asyncio)

    âŒ **NEVER REVERT TO:**
       - asyncio.gather() usage (Rule 997 violation)
       - Custom asyncio coordination
       - Sequential agent execution
       - Manual state routing

    âœ… **ALWAYS MAINTAIN:**
       - Send API for parallel execution
       - StateGraph workflow architecture
       - Dict-based state handling (not TypedDict access)
       - Proper LangGraph node patterns
    """

    def __init__(self, logger_factory: LoggerFactory):
        self.logger_factory = logger_factory
        self.logger = logger_factory.get_api_logger()

        # ðŸ”’ CRITICAL: Build LangGraph StateGraph - DO NOT CHANGE TO CUSTOM ORCHESTRATION
        self.graph = self._build_stategraph()

    def _build_stategraph(self):
        """
        ðŸ”’ **CRITICAL: LangGraph StateGraph construction - MANDATORY PATTERN** ðŸ”’

        This method builds the ONLY approved StateGraph architecture for OAMAT-SD.

        âš ï¸  **WARNING: DO NOT MODIFY THIS ARCHITECTURE**

        The 3-node pattern is mandatory:
        1. distribute_agents: Prepares state for distribution
        2. execute_agent: Executes individual agents in parallel via Send API
        3. collect_results: Collects and merges results

        ðŸš¨ **CRITICAL EDGE PATTERNS:**
        - START â†’ distribute_agents (normal edge)
        - distribute_agents â†’ execute_agent (CONDITIONAL edge with Send routing)
        - execute_agent â†’ collect_results (normal edge)
        - collect_results â†’ END (normal edge)

        The conditional edge is MANDATORY for Send API routing functionality.
        """
        workflow = StateGraph(SmartDecompositionState)

        # ðŸ”’ CRITICAL: Node definitions - DO NOT CHANGE FUNCTION ASSIGNMENTS
        workflow.add_node("distribute_agents", self._prepare_agent_distribution)
        workflow.add_node("execute_agent", self._execute_single_agent)
        workflow.add_node("collect_results", self._collect_agent_results)

        # ðŸ”’ CRITICAL: Edge definitions - CONDITIONAL EDGE MANDATORY FOR SEND API
        workflow.add_edge(START, "distribute_agents")

        # ðŸ”’ **CRITICAL: SEND API ROUTING** - Rules 950/956/999 COMPLIANCE ðŸ”’
        # âš ï¸  DO NOT CHANGE TO add_edge() - BREAKS PARALLEL EXECUTION
        # âš ï¸  Send API REQUIRES add_conditional_edges for routing Send objects
        # âš ï¸  This pattern REVERTED 20+ times - STOP CHANGING IT
        # âš ï¸  Contract violation = immediate system failure
        workflow.add_conditional_edges(
            "distribute_agents",
            self._create_send_objects,  # ðŸ”’ ROUTING function that returns Send objects
            ["execute_agent"],  # Target nodes that Send objects can route to
        )

        workflow.add_edge("execute_agent", "collect_results")
        workflow.add_edge("collect_results", END)

        return workflow.compile()

    async def execute_agents_parallel(
        self, state: SmartDecompositionState
    ) -> SmartDecompositionState:
        """
        ðŸ”’ **MAIN ENTRY POINT: LangGraph StateGraph Parallel Execution** ðŸ”’
        ðŸ“‹ Compliance: Rules 950/956/999 - MANDATORY Send API Implementation

        âš ï¸  **DO NOT REVERT TO ASYNCIO.GATHER** - CONTRACT VIOLATION Rule 999
        âš ï¸  **DO NOT CHANGE TO SEQUENTIAL** - Performance regression
        âš ï¸  **DO NOT MODIFY STATE HANDLING** - LangGraph requirement

        Execute all specialized agents using LangGraph StateGraph with Send API
        """
        specialized_agents = state.get("specialized_agents", {})
        if not specialized_agents:
            raise RuntimeError(
                "No specialized agents available for execution. Cannot proceed without agents."
            )

        self.logger.info("ðŸš€ Starting LangGraph StateGraph agent execution...")

        # Enhanced logging: Log parallel execution start
        execution_start_time = datetime.now()
        self.logger_factory.log_component_operation(
            component="langgraph_execution",
            operation="stategraph_start",
            data={
                "total_agents": len(specialized_agents),
                "agent_roles": list(specialized_agents.keys()),
                "execution_mode": "langgraph_send_api",
                "request_length": len(state.get("user_request", "")),
            },
        )

        try:
            # Convert SmartDecompositionState to dict for StateGraph
            state_dict = {
                "user_request": state.get("user_request", ""),
                "project_path": state.get("project_path", ""),
                "context": state.get("context", {}),
                "specialized_agents": state.get("specialized_agents", {}),
                "agent_outputs": state.get("agent_outputs", {}),
                "current_agent_role": state.get("current_agent_role"),
            }

            # Execute the LangGraph StateGraph
            result_state = await self.graph.ainvoke(state_dict)

            # Calculate execution time
            execution_time = (
                datetime.now() - execution_start_time
            ).total_seconds() * 1000

            # Enhanced logging: Log successful execution
            self.logger_factory.log_component_operation(
                component="langgraph_execution",
                operation="stategraph_complete",
                data={
                    "execution_successful": True,
                    "agents_executed": len(result_state.get("agent_outputs", {})),
                    "execution_mode": "langgraph_send_api",
                },
                execution_time_ms=execution_time,
            )

            # Convert dict result back to SmartDecompositionState
            state["agent_outputs"] = result_state.get("agent_outputs", {})
            state["context"] = result_state.get("context", {})

            self.logger.info(
                f"âœ… LangGraph StateGraph execution complete in {execution_time:.0f}ms"
            )
            return state

        except Exception as e:
            # Enhanced logging: Log execution failure
            execution_time = (
                datetime.now() - execution_start_time
            ).total_seconds() * 1000
            self.logger_factory.log_component_operation(
                component="langgraph_execution",
                operation="stategraph_failed",
                data={
                    "failure_reason": "stategraph_error",
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "execution_time_ms": execution_time,
                },
                execution_time_ms=execution_time,
                success=False,
            )

            self.logger.error(f"LangGraph StateGraph execution failed: {e}")
            raise RuntimeError(
                f"LangGraph agent execution failed: {e}. Cannot proceed without agent results."
            ) from e

    def _prepare_agent_distribution(self, state) -> dict:
        # ðŸ”’ **STATE HANDLING WARNING** - Rules 950/956/804/805 ðŸ”’
        # âš ï¸  state is DICT not SmartDecompositionState (LangGraph converts it)
        # âš ï¸  NEVER use state.attribute - ALWAYS use state.get("attribute")
        # âš ï¸  Return DICT not SmartDecompositionState - LangGraph requirement
        # âš ï¸  This method CRITICAL to Send API - DO NOT MODIFY SIGNATURE
        """
        ðŸ”’ **CRITICAL: Node function for agent distribution preparation** ðŸ”’

        âš ï¸  **STATE HANDLING WARNING - DO NOT CHANGE THESE PATTERNS:**

        1. **Parameter type**: state is dict, NOT SmartDecompositionState
           - LangGraph automatically converts TypedDict to dict during execution
           - NEVER use state.attribute_name syntax
           - ALWAYS use state.get("attribute_name", default)

        2. **Return type**: MUST return dict, NOT SmartDecompositionState
           - LangGraph expects dict return values
           - TypedDict return will cause serialization issues

        ðŸš¨ **CRITICAL**: This is a NODE function, not a routing function
        - Node functions prepare/transform state
        - Routing functions (like _create_send_objects) return Send objects
        - DO NOT mix these responsibilities

        âŒ **NEVER REVERT TO:**
           - def _prepare_agent_distribution(self, state: SmartDecompositionState) -> SmartDecompositionState
           - state.specialized_agents access pattern
           - return SmartDecompositionState(...)

        âœ… **ALWAYS MAINTAIN:**
           - state.get("specialized_agents", {}) access pattern
           - return state (as dict)
           - Type hints as dict, not SmartDecompositionState
        """
        specialized_agents = state.get("specialized_agents", {})
        self.logger.info(
            f"ðŸ“¡ Preparing to distribute to {len(specialized_agents)} agents via Send API"
        )
        # Node function just returns state (routing happens in conditional edge)
        return state

    def _create_send_objects(self, state) -> list[Send]:
        """
        ðŸ”’ **CRITICAL: Routing function that creates Send objects for parallel execution** ðŸ”’

        âš ï¸  **SEND API WARNING - THIS IS THE CORE OF PARALLEL ORCHESTRATION:**

        1. **Purpose**: This function enables LangGraph's native parallel execution
           - Returns Send objects that LangGraph uses for parallel routing
           - Each Send object creates a separate parallel execution path
           - Provides 3-5x performance improvement over sequential execution

        2. **State Creation Pattern**: Create dict states for Send objects
           - LangGraph Send API expects dict states, not TypedDict
           - Each agent gets isolated state with only its own data
           - Use state.get() patterns for safe access

        3. **Send Object Pattern**: Send("target_node", agent_state)
           - "execute_agent" is the target node for all agents
           - Each gets a separate agent_state dict
           - LangGraph automatically merges results

        ðŸš¨ **CRITICAL DEPENDENCIES:**
        - Must be used with add_conditional_edges (NOT add_edge)
        - Target node ("execute_agent") must handle dict states
        - Results automatically merged by LangGraph StateGraph

        âŒ **NEVER REVERT TO:**
           - asyncio.gather() patterns (Rule 997 violation)
           - Custom parallel execution loops
           - Sequential agent execution
           - SmartDecompositionState object creation

        âœ… **ALWAYS MAINTAIN:**
           - Send objects for each agent
           - Dict state creation pattern
           - state.get() access methods
           - Return list[Send] type hint
        """
        # Create Send objects for each agent - this is the LangGraph way
        send_objects = []
        specialized_agents = state.get("specialized_agents", {})

        for agent_role, agent_data in specialized_agents.items():
            # ðŸ”’ CRITICAL: Create agent-specific state as dict (LangGraph uses dicts)
            agent_state = {
                "user_request": state.get("user_request", ""),
                "project_path": state.get("project_path", ""),
                "context": state.get("context", {}),
                "specialized_agents": {agent_role: agent_data},  # Only this agent
                "agent_outputs": {},
                "current_agent_role": agent_role,  # Track which agent this is
            }

            # ðŸ”’ CRITICAL: Create Send object for parallel execution
            send_objects.append(Send("execute_agent", agent_state))

        return send_objects

    async def _execute_single_agent(self, state) -> dict:
        """
        ðŸ”’ **CRITICAL: Single agent execution via Send API - PARALLEL EXECUTION NODE** ðŸ”’

        âš ï¸  **PARALLEL EXECUTION WARNING - THIS RUNS CONCURRENTLY:**

        1. **Execution Context**: This method runs in parallel for each agent
           - Multiple instances execute simultaneously via Send API
           - Each instance gets isolated agent state
           - LangGraph automatically merges results into shared state

        2. **State Handling**: Input state is dict from Send objects
           - NOT SmartDecompositionState (that's converted to dict)
           - Use state.get() for all attribute access
           - Return dict for LangGraph state merging

        3. **Agent Coordination**: Each execution is independent
           - Agent retrieved from specialized_agents dict
           - Invoked via agent.ainvoke() (LangGraph pattern)
           - Results merged automatically by LangGraph

        ðŸš¨ **CRITICAL PERFORMANCE BENEFITS:**
        - Parallel execution provides 3-5x speedup
        - No GIL blocking (different agents, different processes)
        - Native LangGraph optimization
        - Automatic state merging and conflict resolution

        âŒ **NEVER REVERT TO:**
           - Sequential for-loop execution
           - asyncio.gather() coordination (forbidden)
           - Manual state merging logic
           - SmartDecompositionState return objects

        âœ… **ALWAYS MAINTAIN:**
           - async def signature (required for LangGraph)
           - state.get() access patterns
           - Dict return values
           - agent.ainvoke() LangGraph pattern
        """
        agent_role = state.get("current_agent_role")
        specialized_agents = state.get("specialized_agents", {})
        agent_data = specialized_agents[agent_role]
        agent = agent_data["agent"]

        start_time = datetime.now()

        try:
            user_request = state.get("user_request", "")
            context = state.get("context", {})

            # Enhanced logging: Log individual agent execution start
            self.logger_factory.log_agent_lifecycle(
                agent_role=agent_role,
                stage="execution_start",
                data={
                    "request_length": len(user_request),
                    "context_size": len(str(context)),
                    "execution_method": "langgraph_send_api",
                },
            )

            # ðŸ”’ CRITICAL: LangGraph agent invocation pattern
            agent_input = {
                "messages": [
                    HumanMessage(
                        content=f"""USER REQUEST: {user_request}

Please complete your specialized task as a {agent_role} agent. Focus on your specific role and create all required deliverables with high quality.

IMPORTANT:
- Create functional, complete implementations
- Follow best practices for your domain
- Ensure all code is well-documented
- Save files with appropriate names and structure

Your expertise is crucial for this request's success."""
                    )
                ]
            }

            # ðŸ”’ CRITICAL: Execute the LangGraph agent using ainvoke
            result = await agent.ainvoke(agent_input)

            # Extract the response content
            if hasattr(result, "messages") and result.messages:
                # Get the last message content
                last_message = result.messages[-1]
                if hasattr(last_message, "content"):
                    output_content = last_message.content
                else:
                    output_content = str(last_message)
            else:
                output_content = str(result)

            # Calculate execution time
            execution_time = (datetime.now() - start_time).total_seconds() * 1000

            # Enhanced logging: Log successful agent execution
            self.logger_factory.log_agent_lifecycle(
                agent_role=agent_role,
                stage="execution_complete",
                data={
                    "execution_successful": True,
                    "output_length": len(output_content),
                    "execution_mode": "langgraph_send_api",
                },
                execution_time_ms=execution_time,
            )

            self.logger.info(
                f"âœ… Agent {agent_role} completed in {execution_time:.0f}ms"
            )

            # ðŸ”’ CRITICAL: Return state with this agent's output as dict
            # LangGraph automatically merges agent_outputs from all parallel executions
            # IMPORTANT: Do NOT include user_request to avoid concurrent update conflicts
            return {
                "agent_outputs": {agent_role: output_content},  # Merged by LangGraph
            }

        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds() * 1000

            # Enhanced logging: Log agent execution failure
            self.logger_factory.log_agent_lifecycle(
                agent_role=agent_role,
                stage="execution_failed",
                data={
                    "execution_successful": False,
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "execution_mode": "langgraph_send_api",
                    "success": False,
                },
                execution_time_ms=execution_time,
            )

            self.logger.error(f"âŒ Agent {agent_role} failed: {e}")

            # ðŸ”’ CRITICAL: Return state with error information as dict
            # IMPORTANT: Do NOT include user_request to avoid concurrent update conflicts
            return {
                "agent_outputs": {agent_role: f"ERROR: {str(e)}"},
            }

    def _collect_agent_results(self, state) -> dict:
        """Collect results from all agents - LangGraph automatically merges states"""
        self.logger.info("ðŸ“¥ Collecting results from agents")

        # LangGraph converts TypedDict to plain dict during execution
        # Access state fields as dictionary keys
        agent_outputs = state.get("agent_outputs", {})

        self.logger_factory.log_component_operation(
            component="langgraph_execution",
            operation="results_collected",
            data={
                "total_outputs": len(agent_outputs),
                "successful_agents": len(
                    [
                        k
                        for k, v in agent_outputs.items()
                        if not str(v).startswith("ERROR:")
                    ]
                ),
                "failed_agents": len(
                    [k for k, v in agent_outputs.items() if str(v).startswith("ERROR:")]
                ),
            },
        )

        return state
