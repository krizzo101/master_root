#!/usr/bin/env python3\n\"\"\"\nKnowledge Readiness Architecture Test\n===================================\n\nTests the operational Knowledge Readiness Architecture with real scenarios.\nDemonstrates contextual loading, quick reference access, and domain intelligence.\n\"\"\"\n\nimport asyncio\nimport json\nfrom typing import Dict, List, Any\nfrom datetime import datetime\n\nclass KnowledgeReadinessArchitectureTester:\n    \"\"\"\n    Tests Knowledge Readiness Architecture with realistic scenarios.\n    \n    Validates contextual loading, domain discovery, and quick reference systems.\n    \"\"\"\n    \n    def __init__(self):\n        self.test_scenarios = {\n            \"database_operation_context\": {\n                \"user_input\": \"I need to query the cognitive_concepts collection to find reasoning patterns\",\n                \"expected_triggers\": [\"database\", \"query\", \"collection\"],\n                \"expected_domains\": [\"database_operations\", \"behavioral_patterns\"],\n                \"expected_quick_reference\": [\"database_operations\", \"aql_syntax_order\"],\n                \"expected_loading_strategy\": \"immediate_plus_progressive\"\n            },\n            \"tool_selection_context\": {\n                \"user_input\": \"What's the best way to handle file operations in this project?\",\n                \"expected_triggers\": [\"tool\", \"file\"],\n                \"expected_domains\": [\"tool_evolution\", \"behavioral_patterns\"],\n                \"expected_quick_reference\": [\"database_operations\", \"file_operations\"],\n                \"expected_loading_strategy\": \"immediate\"\n            },\n            \"cognitive_enhancement_context\": {\n                \"user_input\": \"I need to think through this complex problem systematically\",\n                \"expected_triggers\": [\"thinking\", \"cognitive\", \"analysis\"],\n                \"expected_domains\": [\"cognitive_research\"],\n                \"expected_quick_reference\": [\"thinking_tool_usage\"],\n                \"expected_loading_strategy\": \"progressive_with_depth\"\n            },\n            \"workflow_orchestration_context\": {\n                \"user_input\": \"How should I coordinate multiple agents for this workflow?\",\n                \"expected_triggers\": [\"workflow\", \"coordination\", \"agents\"],\n                \"expected_domains\": [\"workflow_orchestration\", \"behavioral_patterns\"],\n                \"expected_quick_reference\": [\"parallel_tool_execution\"],\n                \"expected_loading_strategy\": \"immediate_plus_progressive\"\n            },\n            \"knowledge_management_context\": {\n                \"user_input\": \"How do I update the domain taxonomy to include new knowledge?\",\n                \"expected_triggers\": [\"knowledge\", \"domain\", \"taxonomy\"],\n                \"expected_domains\": [\"behavioral_patterns\", \"database_operations\"],\n                \"expected_quick_reference\": [\"knowledge_architecture_patterns\"],\n                \"expected_loading_strategy\": \"immediate_plus_progressive\"\n            }\n        }\n    \n    def simulate_context_detection(self, user_input: str) -> Dict[str, Any]:\n        \"\"\"Simulate context detection from user input\"\"\"\n        \n        input_lower = user_input.lower()\n        detected_contexts = []\n        triggered_keywords = []\n        \n        # Database context detection\n        database_keywords = [\"database\", \"query\", \"arango\", \"collection\", \"backup\", \"aql\"]\n        if any(keyword in input_lower for keyword in database_keywords):\n            detected_contexts.append(\"database_operations\")\n            triggered_keywords.extend([kw for kw in database_keywords if kw in input_lower])\n        \n        # Tool context detection  \n        tool_keywords = [\"tool\", \"mcp\", \"filesystem\", \"shell\", \"file\", \"command\"]\n        if any(keyword in input_lower for keyword in tool_keywords):\n            detected_contexts.append(\"tool_selection\")\n            triggered_keywords.extend([kw for kw in tool_keywords if kw in input_lower])\n        \n        # Cognitive context detection\n        cognitive_keywords = [\"thinking\", \"reasoning\", \"cognitive\", \"analysis\", \"problem\"]\n        if any(keyword in input_lower for keyword in cognitive_keywords):\n            detected_contexts.append(\"cognitive_enhancement\")\n            triggered_keywords.extend([kw for kw in cognitive_keywords if kw in input_lower])\n        \n        # Workflow context detection\n        workflow_keywords = [\"workflow\", \"orchestrator\", \"coordination\", \"agents\", \"multi-step\"]\n        if any(keyword in input_lower for keyword in workflow_keywords):\n            detected_contexts.append(\"workflow_orchestration\")\n            triggered_keywords.extend([kw for kw in workflow_keywords if kw in input_lower])\n        \n        # Knowledge management context detection\n        knowledge_keywords = [\"knowledge\", \"domain\", \"taxonomy\", \"inventory\", \"reference\"]\n        if any(keyword in input_lower for keyword in knowledge_keywords):\n            detected_contexts.append(\"knowledge_management\")\n            triggered_keywords.extend([kw for kw in knowledge_keywords if kw in input_lower])\n        \n        return {\n            \"detected_contexts\": list(set(detected_contexts)),\n            \"triggered_keywords\": list(set(triggered_keywords)),\n            \"confidence\": len(triggered_keywords) / 10.0  # Simple confidence metric\n        }\n    \n    def simulate_domain_loading(self, contexts: List[str]) -> Dict[str, Any]:\n        \"\"\"Simulate domain loading based on detected contexts\"\"\"\n        \n        # Context to domain mapping (from our context_relevance_map)\n        context_domain_map = {\n            \"database_operations\": {\n                \"immediate\": [\"database_operations\", \"behavioral_patterns\"],\n                \"progressive\": [\"tool_evolution\"]\n            },\n            \"tool_selection\": {\n                \"immediate\": [\"tool_evolution\", \"behavioral_patterns\"],\n                \"progressive\": []\n            },\n            \"cognitive_enhancement\": {\n                \"immediate\": [\"cognitive_research\"],\n                \"progressive\": [\"behavioral_patterns\"]\n            },\n            \"workflow_orchestration\": {\n                \"immediate\": [\"workflow_orchestration\", \"behavioral_patterns\"],\n                \"progressive\": [\"cognitive_research\"]\n            },\n            \"knowledge_management\": {\n                \"immediate\": [\"behavioral_patterns\", \"database_operations\"],\n                \"progressive\": [\"cognitive_research\"]\n            }\n        }\n        \n        domains_to_load = {\n            \"immediate\": set(),\n            \"progressive\": set()\n        }\n        \n        for context in contexts:\n            if context in context_domain_map:\n                domains_to_load[\"immediate\"].update(context_domain_map[context][\"immediate\"])\n                domains_to_load[\"progressive\"].update(context_domain_map[context][\"progressive\"])\n        \n        return {\n            \"immediate_domains\": list(domains_to_load[\"immediate\"]),\n            \"progressive_domains\": list(domains_to_load[\"progressive\"]),\n            \"total_domains\": len(domains_to_load[\"immediate\"]) + len(domains_to_load[\"progressive\"]),\n            \"loading_strategy\": \"immediate_plus_progressive\" if domains_to_load[\"progressive\"] else \"immediate\"\n        }\n    \n    def simulate_quick_reference_access(self, contexts: List[str]) -> List[Dict[str, Any]]:\n        \"\"\"Simulate quick reference access based on contexts\"\"\"\n        \n        # Context to quick reference mapping\n        context_quick_ref_map = {\n            \"database_operations\": [\n                {\n                    \"key\": \"database_operations\",\n                    \"title\": \"Database Operation Tool Priority\",\n                    \"quick_answer\": \"mcp_cognitive_tools_arango_* (primary) â†’ mcp_multi_modal_db_arango_* (fallback) â†’ direct AQL (last resort)\"\n                },\n                {\n                    \"key\": \"aql_syntax_order\",\n                    \"title\": \"AQL Query Syntax Order\",\n                    \"quick_answer\": \"FOR â†’ FILTER â†’ SORT â†’ LIMIT â†’ RETURN (MANDATORY ORDER)\"\n                }\n            ],\n            \"tool_selection\": [\n                {\n                    \"key\": \"file_operations\",\n                    \"title\": \"File Operation Tool Priority\", \n                    \"quick_answer\": \"mcp_filesystem_* with absolute paths (/home/opsvi/asea/...) â†’ native tools (deprecated)\"\n                },\n                {\n                    \"key\": \"shell_operations\",\n                    \"title\": \"Shell Command Tool Priority\",\n                    \"quick_answer\": \"mcp_shell_shell_exec (primary) â†’ run_terminal_cmd (fallback) â†’ manual alternatives\"\n                }\n            ],\n            \"cognitive_enhancement\": [\n                {\n                    \"key\": \"thinking_tool_usage\",\n                    \"title\": \"When to Use Thinking Tool\",\n                    \"quick_answer\": \"Use for complex problems, uncertain situations, multi-step planning, or when user says 'think'\"\n                }\n            ],\n            \"workflow_orchestration\": [\n                {\n                    \"key\": \"parallel_tool_execution\",\n                    \"title\": \"Parallel Tool Execution Standard\",\n                    \"quick_answer\": \"Execute multiple read-only operations simultaneously, avoid sequential when parallel possible\"\n                }\n            ],\n            \"knowledge_management\": [\n                {\n                    \"key\": \"knowledge_architecture_patterns\",\n                    \"title\": \"Knowledge Architecture Usage\",\n                    \"quick_answer\": \"Use context-triggered loading, domain taxonomy for organization, quick reference for immediate decisions\"\n                }\n            ]\n        }\n        \n        quick_references = []\n        for context in contexts:\n            if context in context_quick_ref_map:\n                quick_references.extend(context_quick_ref_map[context])\n        \n        return quick_references\n    \n    def run_scenario_test(self, scenario_name: str, scenario: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Run a complete scenario test\"\"\"\n        \n        print(f\"\\nğŸ§ª Testing Scenario: {scenario_name}\")\n        print(f\"   Input: {scenario['user_input']}\")\n        \n        # Step 1: Context Detection\n        context_detection = self.simulate_context_detection(scenario[\"user_input\"])\n        print(f\"   Detected Contexts: {context_detection['detected_contexts']}\")\n        print(f\"   Triggered Keywords: {context_detection['triggered_keywords']}\")\n        print(f\"   Confidence: {context_detection['confidence']:.2f}\")\n        \n        # Step 2: Domain Loading\n        domain_loading = self.simulate_domain_loading(context_detection[\"detected_contexts\"])\n        print(f\"   Immediate Domains: {domain_loading['immediate_domains']}\")\n        print(f\"   Progressive Domains: {domain_loading['progressive_domains']}\")\n        print(f\"   Loading Strategy: {domain_loading['loading_strategy']}\")\n        \n        # Step 3: Quick Reference Access\n        quick_references = self.simulate_quick_reference_access(context_detection[\"detected_contexts\"])\n        print(f\"   Quick References: {len(quick_references)} available\")\n        for qr in quick_references:\n            print(f\"     - {qr['title']}: {qr['quick_answer'][:50]}...\")\n        \n        # Step 4: Validation\n        validation_results = {\n            \"context_detection_accuracy\": len(set(context_detection[\"detected_contexts\"]).intersection(set(scenario.get(\"expected_domains\", [])))) > 0,\n            \"keyword_trigger_accuracy\": len(set(context_detection[\"triggered_keywords\"]).intersection(set(scenario.get(\"expected_triggers\", [])))) > 0,\n            \"domain_loading_accuracy\": len(set(domain_loading[\"immediate_domains\"]).intersection(set(scenario.get(\"expected_domains\", [])))) > 0,\n            \"quick_reference_availability\": len(quick_references) > 0\n        }\n        \n        accuracy_score = sum(validation_results.values()) / len(validation_results)\n        print(f\"   Accuracy Score: {accuracy_score:.2f} ({accuracy_score*100:.0f}%)\")\n        \n        test_result = {\n            \"scenario_name\": scenario_name,\n            \"input\": scenario[\"user_input\"],\n            \"context_detection\": context_detection,\n            \"domain_loading\": domain_loading,\n            \"quick_references\": quick_references,\n            \"validation\": validation_results,\n            \"accuracy_score\": accuracy_score,\n            \"timestamp\": datetime.now().isoformat()\n        }\n        \n        return test_result\n    \n    def run_comprehensive_test(self) -> Dict[str, Any]:\n        \"\"\"Run comprehensive test of Knowledge Readiness Architecture\"\"\"\n        \n        print(\"ğŸš€ Starting Knowledge Readiness Architecture Comprehensive Test...\\n\")\n        \n        test_results = {\n            \"test_session_id\": f\"kra_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n            \"test_timestamp\": datetime.now().isoformat(),\n            \"scenarios_tested\": len(self.test_scenarios),\n            \"individual_results\": [],\n            \"overall_metrics\": {},\n            \"architecture_validation\": {}\n        }\n        \n        # Run individual scenario tests\n        total_accuracy = 0\n        for scenario_name, scenario in self.test_scenarios.items():\n            result = self.run_scenario_test(scenario_name, scenario)\n            test_results[\"individual_results\"].append(result)\n            total_accuracy += result[\"accuracy_score\"]\n        \n        # Calculate overall metrics\n        test_results[\"overall_metrics\"] = {\n            \"average_accuracy\": total_accuracy / len(self.test_scenarios),\n            \"context_detection_success_rate\": sum(1 for r in test_results[\"individual_results\"] if r[\"validation\"][\"context_detection_accuracy\"]) / len(self.test_scenarios),\n            \"domain_loading_success_rate\": sum(1 for r in test_results[\"individual_results\"] if r[\"validation\"][\"domain_loading_accuracy\"]) / len(self.test_scenarios),\n            \"quick_reference_availability_rate\": sum(1 for r in test_results[\"individual_results\"] if r[\"validation\"][\"quick_reference_availability\"]) / len(self.test_scenarios)\n        }\n        \n        # Architecture validation\n        test_results[\"architecture_validation\"] = {\n            \"contextual_loading_functional\": test_results[\"overall_metrics\"][\"context_detection_success_rate\"] > 0.8,\n            \"domain_intelligence_operational\": test_results[\"overall_metrics\"][\"domain_loading_success_rate\"] > 0.8,\n            \"quick_reference_accessible\": test_results[\"overall_metrics\"][\"quick_reference_availability_rate\"] > 0.8,\n            \"overall_architecture_status\": \"OPERATIONAL\" if test_results[\"overall_metrics\"][\"average_accuracy\"] > 0.8 else \"NEEDS_IMPROVEMENT\"\n        }\n        \n        # Print summary\n        print(\"\\n\" + \"=\"*60)\n        print(\"ğŸ¯ KNOWLEDGE READINESS ARCHITECTURE TEST RESULTS\")\n        print(\"=\"*60)\n        print(f\"ğŸ“Š Scenarios Tested: {test_results['scenarios_tested']}\")\n        print(f\"ğŸ¯ Average Accuracy: {test_results['overall_metrics']['average_accuracy']:.2f} ({test_results['overall_metrics']['average_accuracy']*100:.0f}%)\")\n        print(f\"ğŸ” Context Detection: {test_results['overall_metrics']['context_detection_success_rate']:.2f} ({test_results['overall_metrics']['context_detection_success_rate']*100:.0f}%)\")\n        print(f\"ğŸ“š Domain Loading: {test_results['overall_metrics']['domain_loading_success_rate']:.2f} ({test_results['overall_metrics']['domain_loading_success_rate']*100:.0f}%)\")\n        print(f\"âš¡ Quick Reference: {test_results['overall_metrics']['quick_reference_availability_rate']:.2f} ({test_results['overall_metrics']['quick_reference_availability_rate']*100:.0f}%)\")\n        print(f\"ğŸ—ï¸ Architecture Status: {test_results['architecture_validation']['overall_architecture_status']}\")\n        print(\"=\"*60)\n        \n        return test_results\n\ndef main():\n    \"\"\"Main execution function\"\"\"\n    tester = KnowledgeReadinessArchitectureTester()\n    results = tester.run_comprehensive_test()\n    \n    # Save results\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    results_file = f\"/home/opsvi/asea/development/knowledge_management/results/kra_test_results_{timestamp}.json\"\n    \n    with open(results_file, 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    print(f\"\\nâœ… Test results saved to: {results_file}\")\n    \n    return results\n\nif __name__ == \"__main__\":\n    main()\n"
