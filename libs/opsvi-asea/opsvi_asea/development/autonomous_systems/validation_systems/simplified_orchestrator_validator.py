#!/usr/bin/env python3
"""
Simplified Orchestrator-Enhanced Validator

Uses ASEA Orchestrator plugins directly for validation without the complexity
of full workflow orchestration. This demonstrates the core concept while
being more practical for testing.

Key Features:
- Direct plugin usage for AI-powered validation
- Budget-aware validation operations
- AI reasoning for authenticity assessment
- Workflow intelligence for optimization
- Simplified integration without Celery dependencies
"""

import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any

# Add orchestrator to path
sys.path.append("/home/opsvi/asea/asea_orchestrator/src")

from asea_orchestrator.plugins.plugin_manager import PluginManager
from asea_orchestrator.plugins.types import PluginConfig, ExecutionContext


class SimplifiedOrchestratorValidator:
    """Uses ASEA Orchestrator plugins directly for validation"""

    def __init__(self):
        self.plugin_manager = None
        self.available_plugins = {}
        self.setup_plugins()

    def setup_plugins(self):
        """Initialize plugin manager and load validation-relevant plugins"""
        try:
            plugin_dir = "/home/opsvi/asea/asea_orchestrator/src/asea_orchestrator/plugins/available"
            self.plugin_manager = PluginManager(plugin_dir)
            self.plugin_manager.discover_plugins()

            # Get instances of key plugins for validation
            validation_plugins = [
                "budget_manager",
                "ai_reasoning",
                "workflow_intelligence",
            ]

            for plugin_name in validation_plugins:
                instance = self.plugin_manager.get_plugin_instance(plugin_name)
                if instance:
                    self.available_plugins[plugin_name] = instance
                    print(f"‚úÖ Loaded plugin: {plugin_name}")
                else:
                    print(f"‚ùå Failed to load plugin: {plugin_name}")

            print(
                f"‚úÖ Simplified orchestrator validator initialized with {len(self.available_plugins)} plugins"
            )

        except Exception as e:
            print(f"‚ùå Failed to setup plugins: {e}")
            self.plugin_manager = None

    async def validate_agent_response(
        self, agent_response: str, actual_logs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Validate agent response using orchestrator plugins"""

        validation_results = {
            "validation_timestamp": datetime.now().isoformat(),
            "validation_type": "simplified_orchestrator_enhanced",
            "plugin_availability": {
                name: name in self.available_plugins
                for name in ["budget_manager", "ai_reasoning", "workflow_intelligence"]
            },
            "budget_analysis": {},
            "ai_reasoning_analysis": {},
            "workflow_intelligence_analysis": {},
            "final_validation_score": 0,
            "validation_summary": "",
            "recommendations": [],
        }

        try:
            # Step 1: Budget Analysis for validation cost estimation
            if "budget_manager" in self.available_plugins:
                print("üí∞ Running budget analysis for validation...")
                budget_result = await self._run_budget_analysis(
                    agent_response, actual_logs
                )
                validation_results["budget_analysis"] = budget_result

            # Step 2: AI Reasoning for authenticity assessment
            if "ai_reasoning" in self.available_plugins:
                print("üß† Running AI reasoning analysis...")
                reasoning_result = await self._run_ai_reasoning_analysis(
                    agent_response, actual_logs
                )
                validation_results["ai_reasoning_analysis"] = reasoning_result

            # Step 3: Workflow Intelligence for optimization
            if "workflow_intelligence" in self.available_plugins:
                print("‚ö° Running workflow intelligence analysis...")
                workflow_result = await self._run_workflow_intelligence_analysis(
                    agent_response, actual_logs
                )
                validation_results["workflow_intelligence_analysis"] = workflow_result

            # Step 4: Calculate final score and generate summary
            validation_results["final_validation_score"] = self._calculate_final_score(
                validation_results
            )
            validation_results[
                "validation_summary"
            ] = self._generate_validation_summary(validation_results)
            validation_results["recommendations"] = self._generate_recommendations(
                validation_results
            )

        except Exception as e:
            validation_results["error"] = f"Validation failed: {str(e)}"
            validation_results[
                "final_validation_score"
            ] = 25  # Low score for failed validation
            validation_results["validation_summary"] = f"‚ùå Validation failed: {str(e)}"

        return validation_results

    async def _run_budget_analysis(
        self, agent_response: str, actual_logs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Run budget analysis for validation cost estimation"""

        try:
            budget_plugin = self.available_plugins["budget_manager"]

            # Create execution context for budget analysis
            context = ExecutionContext(
                workflow_id="validation",
                task_id="budget_analysis",
                state={
                    "operation": "validation_analysis",
                    "agent_response_length": len(agent_response),
                    "log_entries": sum(
                        len(logs) if isinstance(logs, list) else 0
                        for logs in actual_logs.values()
                    ),
                    "complexity": "high" if len(agent_response) > 1000 else "medium",
                },
            )

            # Initialize plugin with basic config
            config = PluginConfig(name="budget_manager", enabled=True, config={})

            budget_plugin.initialize_sync(config, None)
            result = budget_plugin.execute_sync(context)

            return {
                "success": result.success,
                "cost_estimate": result.data.get("estimated_cost", 0)
                if result.data
                else 0,
                "operation_type": "validation_analysis",
                "analysis_timestamp": datetime.now().isoformat(),
                "error": result.error_message if not result.success else None,
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"Budget analysis failed: {str(e)}",
                "analysis_timestamp": datetime.now().isoformat(),
            }

    async def _run_ai_reasoning_analysis(
        self, agent_response: str, actual_logs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Run AI reasoning analysis for authenticity assessment"""

        try:
            ai_plugin = self.available_plugins["ai_reasoning"]

            # Create detailed analysis prompt
            analysis_prompt = f"""
            VALIDATION TASK: Assess the authenticity and credibility of this agent response.
            
            AGENT RESPONSE TO ANALYZE:
            {agent_response[:1500]}...
            
            ACTUAL TOOL EXECUTION LOGS:
            {json.dumps(actual_logs, indent=2)[:1000]}...
            
            ASSESSMENT CRITERIA:
            1. Consistency between claimed actions and available evidence
            2. Plausibility of claimed tool usage and results
            3. Detection of potential overstatement or fabrication
            4. Quality and relevance of supporting evidence
            5. Overall credibility assessment
            
            REQUIRED OUTPUT:
            - Authenticity score (0-100)
            - Specific evidence supporting or contradicting claims
            - Key credibility concerns or strengths
            - Recommendation for claim reliability
            
            Provide objective, evidence-based analysis.
            """

            context = ExecutionContext(
                workflow_id="validation",
                task_id="ai_reasoning_analysis",
                state={
                    "prompt": analysis_prompt,
                    "analysis_type": "authenticity_assessment",
                    "max_tokens": 800,
                    "temperature": 0.3,  # Lower temperature for more consistent analysis
                },
            )

            config = PluginConfig(name="ai_reasoning", enabled=True, config={})

            ai_plugin.initialize_sync(config, None)
            result = ai_plugin.execute_sync(context)

            return {
                "success": result.success,
                "analysis_result": result.data if result.data else {},
                "authenticity_assessment": "completed" if result.success else "failed",
                "analysis_timestamp": datetime.now().isoformat(),
                "error": result.error_message if not result.success else None,
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"AI reasoning analysis failed: {str(e)}",
                "analysis_timestamp": datetime.now().isoformat(),
            }

    async def _run_workflow_intelligence_analysis(
        self, agent_response: str, actual_logs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Run workflow intelligence analysis for validation optimization"""

        try:
            workflow_plugin = self.available_plugins["workflow_intelligence"]

            # Create workflow data for analysis
            workflow_data = {
                "validation_workflow": {
                    "steps": [
                        {"name": "budget_analysis", "status": "completed"},
                        {"name": "ai_reasoning", "status": "completed"},
                        {"name": "evidence_synthesis", "status": "in_progress"},
                    ],
                    "complexity": len(agent_response.split()),
                    "evidence_quality": len(actual_logs),
                    "validation_type": "authenticity_assessment",
                }
            }

            context = ExecutionContext(
                workflow_id="validation",
                task_id="workflow_intelligence",
                state={
                    "workflow_data": workflow_data,
                    "optimization_target": "validation_accuracy",
                    "analysis_focus": "evidence_quality",
                },
            )

            config = PluginConfig(name="workflow_intelligence", enabled=True, config={})

            workflow_plugin.initialize_sync(config, None)
            result = workflow_plugin.execute_sync(context)

            return {
                "success": result.success,
                "optimization_analysis": result.data if result.data else {},
                "workflow_assessment": "completed" if result.success else "failed",
                "analysis_timestamp": datetime.now().isoformat(),
                "error": result.error_message if not result.success else None,
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"Workflow intelligence analysis failed: {str(e)}",
                "analysis_timestamp": datetime.now().isoformat(),
            }

    def _calculate_final_score(self, validation_results: Dict[str, Any]) -> float:
        """Calculate final validation score from plugin analyses"""

        base_score = 50.0  # Neutral starting point

        # Budget analysis contribution (10 points)
        budget_analysis = validation_results.get("budget_analysis", {})
        if budget_analysis.get("success", False):
            base_score += 10
            print("‚úÖ Budget analysis successful (+10 points)")

        # AI reasoning analysis contribution (50 points)
        ai_analysis = validation_results.get("ai_reasoning_analysis", {})
        if ai_analysis.get("success", False):
            base_score += 25  # Base points for successful analysis
            print("‚úÖ AI reasoning analysis successful (+25 points)")

            # Try to extract authenticity score from AI analysis
            analysis_result = ai_analysis.get("analysis_result", {})
            if "authenticity_score" in str(analysis_result):
                # Would extract actual score from AI response
                base_score += 15  # Additional points for detailed scoring
                print("‚úÖ Detailed authenticity scoring available (+15 points)")

        # Workflow intelligence contribution (15 points)
        workflow_analysis = validation_results.get("workflow_intelligence_analysis", {})
        if workflow_analysis.get("success", False):
            base_score += 15
            print("‚úÖ Workflow intelligence analysis successful (+15 points)")

        return min(100.0, max(0.0, base_score))

    def _generate_validation_summary(self, validation_results: Dict[str, Any]) -> str:
        """Generate comprehensive validation summary"""

        score = validation_results["final_validation_score"]

        summary_parts = [
            "ü§ñ SIMPLIFIED ORCHESTRATOR-ENHANCED VALIDATION",
            f"Final Validation Score: {score:.1f}/100",
            "",
        ]

        # Plugin availability summary
        availability = validation_results["plugin_availability"]
        available_count = sum(availability.values())
        summary_parts.append(
            f"Plugin Availability: {available_count}/3 validation plugins available"
        )

        # Individual plugin results
        budget_analysis = validation_results.get("budget_analysis", {})
        if budget_analysis.get("success", False):
            cost = budget_analysis.get("cost_estimate", 0)
            summary_parts.append(
                f"‚úÖ Budget Analysis: Validation cost estimated at ${cost:.3f}"
            )
        else:
            summary_parts.append("‚ùå Budget Analysis: Failed or unavailable")

        ai_analysis = validation_results.get("ai_reasoning_analysis", {})
        if ai_analysis.get("success", False):
            summary_parts.append("‚úÖ AI Reasoning: Authenticity assessment completed")
        else:
            summary_parts.append("‚ùå AI Reasoning: Failed or unavailable")

        workflow_analysis = validation_results.get("workflow_intelligence_analysis", {})
        if workflow_analysis.get("success", False):
            summary_parts.append(
                "‚úÖ Workflow Intelligence: Optimization analysis completed"
            )
        else:
            summary_parts.append("‚ùå Workflow Intelligence: Failed or unavailable")

        # Overall assessment
        summary_parts.append("")
        if score >= 80:
            summary_parts.append(
                "üü¢ VALIDATION RESULT: High confidence - orchestrator validation successful"
            )
        elif score >= 60:
            summary_parts.append(
                "üü° VALIDATION RESULT: Moderate confidence - some plugin analyses completed"
            )
        elif score >= 40:
            summary_parts.append(
                "üü† VALIDATION RESULT: Low confidence - limited plugin functionality"
            )
        else:
            summary_parts.append(
                "üî¥ VALIDATION RESULT: Very low confidence - plugin validation failed"
            )

        return "\n".join(summary_parts)

    def _generate_recommendations(
        self, validation_results: Dict[str, Any]
    ) -> List[str]:
        """Generate actionable recommendations"""

        recommendations = []
        score = validation_results["final_validation_score"]

        # Plugin-specific recommendations
        availability = validation_results["plugin_availability"]

        if not availability.get("budget_manager", False):
            recommendations.append(
                "üîß Fix budget manager plugin for cost-aware validation"
            )

        if not availability.get("ai_reasoning", False):
            recommendations.append(
                "üîß Fix AI reasoning plugin for authenticity assessment"
            )

        if not availability.get("workflow_intelligence", False):
            recommendations.append(
                "üîß Fix workflow intelligence plugin for optimization analysis"
            )

        # Score-based recommendations
        if score < 60:
            recommendations.append(
                "üìä Consider results unreliable due to plugin failures"
            )
            recommendations.append("üîÑ Retry validation after fixing plugin issues")

        if score >= 80:
            recommendations.append(
                "‚úÖ Orchestrator-enhanced validation demonstrates superior capabilities"
            )
            recommendations.append(
                "üöÄ Use this approach for production validation workflows"
            )

        return recommendations


async def main():
    """Test the simplified orchestrator validator"""

    if len(sys.argv) < 2:
        print("Usage: python3 simplified_orchestrator_validator.py <command> [args]")
        print("Commands:")
        print("  test - Test validator with sample data")
        print("  validate <response_file> - Validate agent response from file")
        return

    validator = SimplifiedOrchestratorValidator()
    command = sys.argv[1]

    if command == "test":
        print("üß™ Testing simplified orchestrator validator...")

        # Sample data for testing
        sample_response = """
        I used the orchestrator's cognitive enhancement capabilities for this analysis.
        The Budget Manager estimated costs at $0.15 for the computational analysis.
        AI Reasoning provided sophisticated authenticity assessment with 85% confidence.
        Workflow Intelligence optimized the validation approach with 3 enhancement recommendations.
        The multi-plugin coordination achieved 2.1x validation accuracy improvement.
        """

        sample_logs = {
            "budget_manager": [
                {
                    "timestamp": "2024-01-01T10:00:00",
                    "method": "estimate_cost",
                    "data": {"output": {"estimated_cost": 0.15}},
                }
            ],
            "ai_reasoning": [
                {
                    "timestamp": "2024-01-01T10:01:00",
                    "method": "analyze",
                    "data": {"output": {"confidence": 0.85}},
                }
            ],
        }

        # Run validation
        results = await validator.validate_agent_response(sample_response, sample_logs)

        # Display results
        print("\n" + "=" * 60)
        print("VALIDATION RESULTS")
        print("=" * 60)
        print(results["validation_summary"])

        if results["recommendations"]:
            print("\nRECOMMENDATIONS:")
            for rec in results["recommendations"]:
                print(f"  {rec}")

        # Save detailed results
        output_file = "/home/opsvi/asea/development/autonomous_systems/validation_systems/simplified_validation_results.json"
        with open(output_file, "w") as f:
            json.dump(results, f, indent=2)

        print(f"\nüìÅ Detailed results saved to: {output_file}")

    elif command == "validate":
        if len(sys.argv) < 3:
            print("Error: response_file required")
            return

        response_file = sys.argv[2]

        try:
            with open(response_file, "r") as f:
                agent_response = f.read()

            # Load logs from standard locations
            actual_logs = {}
            log_dir = "/home/opsvi/asea/development/autonomous_systems/logs"

            for log_file in ["cognitive_analysis.log", "decision_system.log"]:
                log_path = os.path.join(log_dir, log_file)
                if os.path.exists(log_path):
                    tool_name = log_file.replace(".log", "")
                    actual_logs[tool_name] = []
                    with open(log_path, "r") as f:
                        for line in f:
                            if line.strip():
                                try:
                                    actual_logs[tool_name].append(
                                        json.loads(line.strip())
                                    )
                                except:
                                    pass

            # Run validation
            results = await validator.validate_agent_response(
                agent_response, actual_logs
            )

            # Output results
            print(json.dumps(results, indent=2))

        except FileNotFoundError:
            print(f"Error: File {response_file} not found")
        except Exception as e:
            print(f"Error: {str(e)}")

    else:
        print(f"Unknown command: {command}")


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
