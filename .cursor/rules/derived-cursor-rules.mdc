---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## Headers

This document outlines the rules, guidelines, and best practices for the AI coding assistant to effectively assist with software development projects. It covers various aspects, including coding standards, project structure, workflow, and debugging. This document is a "living" file, updated with each new interaction with the AI to ensure continuous improvement and alignment with project needs.

## TECH STACK

*   Python 3.x
*   [List any other relevant technologies]
*   FastAPI
*   uvicorn
*   qdrant-client
*   openai
*   playwright
*   pydantic
*   httpx
*   python-dotenv
*   aiohttp
*   tiktoken
*   pytest
*   mypy
*   ruff
*   pydantic-settings
*   tsx

## PROJECT DOCUMENTATION & CONTEXT SYSTEM

*   All project-related documentation should be stored in the appropriate directories, with clear and concise naming conventions.
*   The AI should maintain an understanding of the project's context, including its goals, architecture, and dependencies.
*   [Add any specific documentation tools or formats]
*   The AI should prioritize reading the following files to understand project structure:
    *   `recommended_structure.yaml`: Complete library ecosystem definition.
    *   `templates.yaml`: Comprehensive template registry.
    *   `generate_ecosystem_v2.py`: Advanced ecosystem generator.
    *   `.proj-intel/project_analysis.jsonl`: Primary analysis data.
    *   `.proj-intel/project_analysis.index.json`: Index for selective reads.
    *   `.proj-intel/reverse_index.json`: O(1) path lookup.
    *   `agent_architecture.jsonl`: Agent class definitions.
    *   `INTEGRATIONS_DIRECTORY_TREE.md`: Detailed integration mapping.
*   Before reviewing or using data in `.proj-intel`, the agent needs to read and understand the `AGENT_ONBOARDING.md` file, explaining what data is available, how to access it, and why it should do so.
*   The stats listed regarding the size of the index file, the agent/class definitions, etc are a snapshot in time and should not be given as hardcoded real numbers because they are always changing.
*   The agent needs to check the current timestamps on project intelligence data versus the date/time they observed at startup and determine whether they need to run 'project-intelligence full-package' from the project root in order to refresh the data. It should do this every time to ensure it has the very latest information.
*   The `.mcp.json` file in the project root of this project defines the tools the claude code app has available and is located at: `/home/opsvi/master_root/.mcp.json`.
*   When asked to perform online research regarding the 'claude code' application, focus on understanding its command-line usage, capabilities, and functionality.

## üîÑ MANDATORY: GIT COMMIT REQUIREMENTS (DEFAULT BEHAVIOR - CANNOT BE IGNORED)

### CRITICAL: FREQUENT COMMITTING IS MANDATORY
**Git commits are NOT optional** - they are a fundamental requirement for all development work. This is default behavior that cannot be skipped, ignored, or postponed.

### MANDATORY COMMIT TRIGGERS (NO EXCEPTIONS)
**You MUST commit after:**
*   **EVERY functional change** - Any code that adds, fixes, or modifies functionality
*   **EVERY logical unit of work** - Complete a feature, fix a bug, then commit
*   **EVERY file modification** - After editing any file, commit the changes
*   **BEFORE switching tasks** - Never leave uncommitted work when changing focus
*   **AFTER any significant refactoring** - Code improvements that enhance performance/functionality
*   **AFTER fixing errors** - Any bug fixes or error corrections
*   **AFTER implementing features** - New functionality or capabilities

### COMMIT FREQUENCY REQUIREMENTS
*   **MINIMUM**: Commit after every 2-3 file changes
*   **TARGET**: Commit after every logical unit of work
*   **MAXIMUM**: Never let more than 10 file changes go uncommitted
*   **EMERGENCY**: If approaching token limits or session issues, commit immediately

### GIT COMMIT PROTOCOL (MANDATORY EXECUTION)
```bash
# MANDATORY COMMIT SEQUENCE - EXECUTE AFTER EVERY LOGICAL UNIT OF WORK
git add -A
git diff --cached --quiet --ignore-submodules -- || git commit --no-verify -m "chore: autosave commit of all changes ($(date -u +%Y-%m-%dT%H:%M:%SZ))"
pwd
ls -a
git status | cat
git branch --show-current
git log --oneline -5 | cat
git worktree list | cat
```

### COMMIT MESSAGE STANDARDS (ENFORCED)
*   **Format**: `chore: autosave commit of all changes (YYYY-MM-DDTHH:MM:SSZ)`
*   **Include timestamp**: Always use UTC timestamp in commit message
*   **Use --no-verify**: Skip hooks that might block commits
*   **Descriptive when needed**: For major changes, include brief description
*   **Atomic commits**: Each commit should represent one logical change

### GIT STATUS MONITORING (CONTINUOUS)
*   **BEFORE every operation**: Check `git status` to understand current state
*   **AFTER every operation**: Verify changes are tracked and committed
*   **REGULAR checks**: Monitor working directory cleanliness
*   **BRANCH awareness**: Always know which branch you're working on

### COMMIT FAILURE PROTOCOLS
*   **If commit fails**: Investigate immediately, don't continue without committing
*   **If hooks block**: Use `--no-verify` flag to bypass non-critical hooks
*   **If merge conflicts**: Resolve immediately, don't leave conflicts uncommitted
*   **If large files**: Commit anyway, address size issues in separate commit

### WORKFLOW INTEGRATION
*   **Commit first, then continue**: Never proceed to next task without committing
*   **Commit before breaks**: Always commit before taking breaks or switching contexts
*   **Commit for safety**: Use commits as checkpoints for rollback capability
*   **Commit for tracking**: Maintain clear history of all changes and decisions

### ENFORCEMENT RULES
*   ‚ùå **VIOLATION**: Making changes without committing
*   ‚ùå **VIOLATION**: Switching tasks with uncommitted work
*   ‚ùå **VIOLATION**: Leaving work uncommitted overnight
*   ‚ùå **VIOLATION**: Ignoring git status warnings
*   ‚úÖ **COMPLIANT**: Committing after every logical unit of work
*   ‚úÖ **COMPLIANT**: Using proper commit messages with timestamps
*   ‚úÖ **COMPLIANT**: Monitoring git status continuously

### AUTOMATIC COMMIT TRIGGERS
The system will automatically trigger commits when:
*   **File count threshold**: More than 5 files modified
*   **Time threshold**: More than 30 minutes since last commit
*   **Task completion**: Logical unit of work finished
*   **Error recovery**: After fixing issues or rolling back changes
*   **Session safety**: Before any operation that might cause session issues

## CODING STANDARDS

*   Adhere to PEP 8 guidelines for Python code.
*   Write clear, concise, and well-commented code.
*   Use meaningful variable and function names.
*   Follow established design patterns and architectural principles.
*   Ensure code is modular and reusable.
*   Handle errors gracefully using try-except blocks.
*   Always include comprehensive docstrings for all functions and classes.
*   Follow SOLID principles and DRY approach.
*   Use Async/await throughout for scalability.
*   Use comprehensive type hints with MyPy.
*   Use Pydantic for configuration validation.
*   Use structured logging with correlation IDs.
*   Design components with BaseComponent inheritance.
*   Use dependency injection for loose coupling.
*   Implement event-driven communication between components.
*   Design for configuration-driven behavior.
*   Implement input validation and sanitization.
*   Use authentication and authorization mechanisms.
*   Implement audit logging and security event tracking.
*   Integrate vulnerability scanning.

## WORKFLOW & RELEASE RULES

*   Follow a Git-based workflow for version control.
*   Use feature branches for new development.
*   Create pull requests for code review.
*   All code must be reviewed and approved before merging.
*   Implement automated testing and CI/CD pipelines.
*   Always use `shell_exec` instead of `run_terminal_cmd` for executing commands.
*   When committing changes to git, include a special note in the description if the claude code MCP server is working properly.
*   When I ask you to generate a diagram, I expect it to be rendered inline in the chat session.
*   When the user requests a git commit without specifying a commit message, propose a generic commit message such as "chore: commit all changes [skip ci]".
*   When committing changes via `shell_exec`, the AI should:
    *   Stage all changes using `git add -A`.
    *   Check if there are any changes to commit using `git diff --cached --quiet --ignore-submodules --`.
    *   If there are changes, commit with a message formatted with the current date and time: `git commit --no-verify -m "chore: autosave commit of all changes ($(date -u +%Y-%m-%dT%H:%M:%SZ))"`.
    *   Print the current working directory using `pwd`.
    *   List all files in the directory using `ls -a`.
    *   Show the git status using `git status | cat`.
    *   Show the current branch using `git branch --show-current`.
    *   Show the last 5 commits using `git log --oneline -5 | cat`.
    *   List git worktrees using `git worktree list | cat`.
    *   Provide a summary of the commit, including the branch name, commit hash, commit message, and the number of files changed. Also include the state of the working tree (clean or not). If the working tree is clean and the commit is on a feature branch, suggest the command to push to the remote.
    *   Include a JSON structured summary that includes all required metrics like actions, validation status, time, assumptions, and risks. It‚Äôs crucial to keep this minimal and maintain accuracy with the numbers reported.
*   The AI should batch work whenever appropriate, by default.
*   The AI should use parallel operations as a default behavior.
*   When using `grep` or `find` commands, the AI should use project intel methods as a primary behavior. If the project intel methods don't return anything but it is convinced what they are looking for exists then they should fall back to grep/find. If the grep/find they need to use isn't applicable to the information in the project intel cache then this does not apply which may often be the case for grep, but shouldn't usually be for find if it's a project code file.

## DEBUGGING

*   Use logging for debugging purposes.
*   Include detailed error messages.
*   Utilize debugging tools and techniques to identify and resolve issues.

## STYLE & FORMATTING

*   Use Markdown for documentation.
*   Format code blocks with proper syntax highlighting.
*   Keep lines concise for readability.
*   When presenting the chat name in the matrix, strip off the date and file extension for cleaner presentation.
*   **CRITICAL CONTRAST RULE**: Dark text must be overlaid on a light background or vice versa. NEVER light on light or dark on dark.
*   **MANDATORY CONTRAST CHECK**: Always verify all text-background combinations for sufficient contrast.

## CHAT LOG PROCESSING SCRIPTS

*   Two Python scripts are available for processing chat logs:
    *   `collapse_chat_log.py`: Collapses tool calls into summary lines with truncation.
    *   `log_stripper.py`: Completely removes tool calls into summary lines with truncation.
*   The `log_stripper.py` script removes thoughts and tool calls completely from a chat log to create a clean version with only user and assistant messages for better readability.
*   When using the log processing scripts:
    *   The `input` argument specifies the input chat log file.
    *   The `output` argument specifies the output file.

## CHAT LOG ANALYSIS

*   A Python script `chat_log_analyzer.py` is available for analyzing chat logs. It reports:
    *   Number of lines
    *   Number of user prompts (detects formats like `_**User**_`, `User:`, `User input:`, `Human:`, `<user>`, `User says:`, etc.)
    *   Number of assistant responses (detects formats like `_**Assistant**_`, `Assistant:`, `AI:`, `<assistant>`, `Response:`, `Bot:`, etc.)
    *   Number of tool calls without a preceding `<think>` tag
    *   Number of thoughts `<think> </think> </think>` pairs
    *   Tool Calls per Line (Percentage)
    *   Thoughts per Line (Percentage)
    *   Assistant/User Ratio

*   A Python script `batch_analyze.py` is available for batch processing of chat logs. It runs the `chat_log_analyzer.py` script on all `.md` files in a specified directory and generates a summary report.

*   A Python script `metrics_matrix.py` is available for displaying chat log metrics in a matrix format for easy comparison.
    *   The chat name is stripped of the date and file extension for cleaner presentation.
    *   The matrix is sorted by the number of lines in descending order.
    *   The Tool % and A/U columns are dropped from the matrix for a more focused view.

*   A Python script `comprehensive_analyzer.py` is available for comprehensive chat log analysis and formatting. It reports:
    *   Chat: The chat log name.
    *   Lines (Before): Total lines before formatting.
    *   Lines (After): Total lines after formatting.
    *   Chars: Total characters.
    *   Words: Total words.
    *   Tokens: Total tokens.
    *   Tool: Number of tool calls.
    *   Prompt: Number of user/assistant prompt/response cycles. 1 response to 1 prompt = 1 cycle
    *   Think: Number of `<think> </think> </think>` pairs
    *   Blank: Number of blank lines
    *   Tools Used: Unique list of tools used in the chat file, comma-separated.
    *   It also creates a formatted copy of each chat log in a sub-folder named `_formatted` with the following rules:
        *   No more than one consecutive blank line.
        *   Same for lines that only have `---`.
        *   Tool calls `<details> </details>` are collapsed into a single line and carriage returns are replaced with `||`.
        *   Think blocks `<think> </think> </think>` are collapsed into a single line and carriage returns are replaced with `||`.
    *   Matrix must be presented as a table in the chat response
    *   The `.csv` output needs to be written to `/tmp`.

*   A Python script `enhanced_analyzer.py` is available for further analysis and formatted reporting of chat logs. It generates multiple views of the data, including:
    *   Executive Summary
    *   File Categories Report
    *   Tool Usage Analysis
    *   Content Quality Report
    *   Detailed Data (existing CSV format)

## LIBRARY MIGRATION STRATEGY

### General Strategy
Leverage existing, proven interfaces and implementations from the `agent_world/src/shared` directory as a foundation for the `libs/` directory. Adapt these implementations to the OPSVI template structure while maintaining compatibility during the transition.

### Priority Implementation Order
```yaml
Phase 1 (Immediate):
  - opsvi-llm: Migrate OpenAI interfaces
  - opsvi-http: Migrate HTTP client interface
  - opsvi-data: Migrate database interfaces

Phase 2 (Short-term):
  - opsvi-rag: Implement vector store adapters
  - opsvi-orchestration: Migrate CrewAI/LangGraph interfaces
  - opsvi-memory: Implement caching systems

Phase 3 (Medium-term):
  - opsvi-agents: Implement multi-agent framework
  - opsvi-monitoring: Add observability
  - opsvi-security: Add security layers
```

### Specific Migration Tasks
```python
# OpenAI Interfaces ‚Üí opsvi-llm
intake/custom/agent_world/src/shared/openai_interfaces/
  ‚Üí libs/opsvi-llm/opsvi_llm/providers/openai_provider.py

# HTTP Client ‚Üí opsvi-http  
intake/custom/agent_world/src/shared/interfaces/http/
  ‚Üí libs/opsvi-http/opsvi_http/client/base.py

# Database Interfaces ‚Üí opsvi-data
intake/custom/agent_world/src/shared/interfaces/database/
  ‚Üí libs/opsvi-data/opsvi_data/providers/graph/arangodb_adapter.py

# MCP Integration ‚Üí opsvi-orchestration
intake/custom/agent_world/src/shared/mcp/
  ‚Üí libs/opsvi-orchestration/opsvi_orchestration/integrations/research_tools/
```

### Architecture Improvements

Enhance OPSVI with Agent World Patterns:
*   Collaboration Framework: Integrate into opsvi-agents
*   Intelligent Relevance Scoring: Add to opsvi-rag
*   Pattern-based Agent Selection: Implement in opsvi-orchestration
*   Performance Metrics: Add to opsvi-monitoring

### Agent World Architecture Assessment

The `agent_world` implementation represents a sophisticated, production-ready multi-agent orchestration platform with distinct layers.

#### Core Infrastructure (Fully Implemented)

1.  **API Layer** (`src/api/`):
    *   FastAPI application with comprehensive REST endpoints.
    *   WebSocket support for real-time updates.
    *   Pipeline execution, status tracking, artifact management.
    *   Health checks and queue monitoring.

2.  **Orchestration Engine** (`src/orchestrator/`):
    *   Meta-orchestrator for pipeline coordination.
    *   DAG-based workflow execution.
    *   Task registry and dependency management.
    *   Celery integration for distributed task processing.

3.  **Memory System** (`src/memory/`):
    *   Neo4j graph database for lineage tracking.
    *   Comprehensive schema for projects, runs, tasks, artifacts.
    *   Query system for complex graph operations.

4.  **Worker System** (`src/workers/`):
    *   Celery-based task execution.
    *   8 specialized task types (plan, spec, research, code, test, validate, document, critic).
    *   Metrics tracking and performance monitoring.

#### Application Layer (Extensive Implementation)

1.  **Agent Hub** (`src/applications/agent_hub/`):
    *   Multi-agent system with 10+ specialized agents.
    *   Agent discovery and service registration.
    *   MCP (Model Context Protocol) compliance.
    *   Dashboard and visualization tools.

2.  **SpecStory Intelligence** (`src/applications/specstory_intelligence/`):
    *   Advanced conversation intelligence.
    *   Atomic parsing and conceptual analysis.
    *   Database storage and pipeline integration.
    *   1,500+ lines of sophisticated analysis code.

3.  **Code Generation** (`src/applications/code_gen/`):
    *   AI-powered code generation pipeline.
    *   Test generation and validation.
    *   Documentation generation.
    *   Rate limiting and audit logging.

4.  **Multi-Agent Orchestration** (`src/applications/multi_agent_orchestration/`):
    *   Workflow orchestration system.
    *   Research and task agents.
    *   Communication broker.
    *   Demo and production modes.

#### Shared Infrastructure (Production-Ready)

1.  **OpenAI Interfaces** (20+ files, 1,000+ lines)
    *   Complete OpenAI API coverage.
    *   Authentication and error handling.
    *   Specialized interfaces for each API endpoint.

2.  **MCP Integration** (15+ files, 2,000+ lines)
    *   Brave Search, Firecrawl, ArXiv, Context7.
    *   Research workflow tools.
    *   Neo4j MCP client.
    *   Intelligent relevance scoring.

3.  **Database Interfaces** (10+ files, 3,000+ lines)
    *   ArangoDB (1,112 lines - comprehensive).
    *   PostgreSQL, MySQL, Redis, Elasticsearch.
    *   S3 and consolidated operations.

4.  **Collaboration Framework** (849 lines)
    *   SpecStory Intelligence Pipeline integration.
    *   Agent Hub communication.
    *   Pattern-based agent selection.
    *   Performance metrics and learning.

### Key Strengths & Innovations

#### Production-Ready Architecture

*   **Scalable**: Celery-based distributed processing.
*   **Observable**: Comprehensive logging and metrics.
*   **Reliable**: Error handling and retry mechanisms.
*   **Maintainable**: Well-structured codebase with clear separation.

#### Advanced Multi-Agent System

*   **10+ Specialized Agents**: dev_agent, sentinel, kb_updater, graph_analyst, etc.
*   **Intelligent Routing**: Pattern-based agent selection.
*   **Collaborative Problem Solving**: Multi-agent orchestration.
*   **Learning & Adaptation**: Performance tracking and improvement.

#### Comprehensive Integration

*   **MCP Ecosystem**: Full Model Context Protocol implementation.
*   **Database Support**: Multiple database types with unified interfaces.
*   **API Coverage**: Complete OpenAI API integration.
*   **Research Tools**: Advanced web scraping and analysis.

#### Sophisticated Intelligence Pipeline

*   **Conversation Intelligence**: Deep analysis of chat patterns.
*   **Atomic Parsing**: Granular content analysis.
*   **Conceptual Synthesis**: High-level pattern recognition.
*   **Lineage Tracking**: Complete audit trail

### Updated Migration Strategy

The peer codebase analysis reveals **exceptional coverage** for the OPSVI libs/ architecture. With proper migration from the peer codebases, we can achieve **88% coverage** of the required OPSVI libraries. The new peer codebases to investigate are:

*   `/home/opsvi/master_root/intake/custom/asea`
*   `/home/opsvi/master_root/intake/custom/auto_forge`
*   `/home/opsvi/master_root/intake/custom/docRuleGen`
*   `/home/opsvi/master_root/intake/custom/master`

#### Updated Priorities

1.  Focus on building the **Foundation Layer** first, then systematically address the **Service Layer** gaps, using industry best practices and OPSVI architecture patterns.

2.  Start with **Phase 1 (Core Infrastructure)** to establish the foundation, then proceed systematically through the phases. This approach maximizes value while minimizing risk.

### Updated Agent World Architecture Assessment

The peer codebase analysis reveals **exceptional coverage** for the OPSVI libs/ architecture. With proper migration from the peer codebases, we can achieve **88% coverage** of the required OPSVI libraries.

### New Peer Codebases

The new peer codebases to investigate are:

*   `/home/opsvi/master_root/intake/custom/asea`
*   `/home/opsvi/master_root/intake/custom/auto_forge`
*   `/home/opsvi/master_root/intake/custom/docRuleGen`
*   `/home/opsvi/master_root/intake/custom/master`
*   `/home/opsvi/master_root/intake/custom/graphRAG`
*   `/home/opsvi/master_root/intake/custom/graphiti`
*   `/home/opsvi/master_root/intake/custom/graph_rag`
*   `/home/opsvi/master_root/intake/custom/graph_rag2`
*   `/home/opsvi/master_root/intake/custom/SKG_Cursor`
*   `/home/opsvi/master_root/intake/custom/ide_contex_visualization`

## Actionable Migration Guidance

The agent_world is eventually going away, so the following steps need to be taken:

1.  Create a map of agent\_world -&gt; master\_root/libs
2.  Port into this environment to get things online and ready faster
3.  Use proven code

## Using Shell Exec

Always use `shell_exec`, not `run_terminal_cmd`

When extracting or manipulating files, the AI should:
*   Log the current directory.
*   List all files in the target directory.
*   Check the git status if the target directory is a git repository.
*   Request human confirmation before performing actions, especially if multiple files match the criteria.
*   If multiple files match the criteria, use a loop or wildcard to process all matching files.
*   Ensure the target directory exists before attempting to change into it.
*   After extracting files, the AI should ask if the user wants to remove the archive or list the extracted contents.
*   If a git lock file is encountered, attempt to remove it using `rm -f .git/index.lock`.

## Consult Agent Usage Rules

### Core Purpose

This rule governs how to properly integrate and use consult agents for development tasks requiring expert guidance, complex planning, production-ready code generation, or architectural decision-making. **Use when INTEGRATING CONSULT AGENTS to ENFORCE PATTERNS for QUALITY DEVELOPMENT**

### Key Requirements

#### 1. Pattern Recognition Triggers

The rule specifies WHEN to use consult agents:
- Development tasks requiring expert guidance
- Complex implementation planning
- Production-ready code generation
- Architectural decision-making

#### 2. Session Management Strategy

- **Context Preservation**: Use specific, descriptive session IDs for related tasks
- **Session Tracking**: Maintain session state on requesting agent side
- **Context Quality**: Same session for iterative development, new session for unrelated tasks
- **Memory Architecture**: 1-hour timeout, last 3 exchanges preserved, automatic cleanup

#### 3. Parameter Optimization

- **Auto-Selection Trust**: Let intelligent gatekeeper determine optimal parameters
- **Model Selection**: gpt-5-nano for code, o3 for architecture, gpt-5-mini for documentation
- **Quality Control**: Enable critic for production code, disable for simple queries
- **Iteration Strategy**: 1 for simple tasks, 2 for complex, 3 for critical systems

#### 4. Prompt Engineering Patterns

- **Code Generation**: TASK + LANGUAGE/RUNTIME + INPUTS + CONSTRAINTS + OUTPUT_FORMAT
- **Architecture Planning**: ROLE + OBJECTIVE + CONTEXT + DELIVERABLES + FORMAT + RULES
- **Documentation**: TARGET_AUDIENCE + DOC_TYPE + PRODUCT_CONTEXT + MUST_INCLUDE + TONE

Always use `shell_exec`, not `run_terminal_cmd`

#### New Rule: Parameter Optimization
- **Auto-Selection Trust**: Let intelligent gatekeeper determine optimal parameters
- **Model Selection**: gpt-5-nano for code, o3 for architecture, gpt-5-mini for documentation
- **Quality Control**: Enable critic for production code, disable for simple queries
- **Iteration Strategy**: 1 for simple tasks, 2 for complex, 3 for critical systems

#### New Rule: Pattern Recognition Triggers

The rule specifies WHEN to use consult agents:
- Development tasks requiring expert guidance
- Complex implementation planning
- Production-ready code generation
- Architectural decision-making

#### New Rule: Prompt Engineering Patterns

- **Code Generation**: TASK + LANGUAGE/RUNTIME + INPUTS + CONSTRAINTS + OUTPUT_FORMAT
- **Architecture Planning**: ROLE + OBJECTIVE + CONTEXT + DELIVERABLES + FORMAT + RULES
- **Documentation**: TARGET_AUDIENCE + DOC_TYPE + PRODUCT_CONTEXT + MUST_INCLUDE + TONE

Always use `shell_exec`, not `run_terminal_cmd`

### Example Consult Agent Call
When using a consult agent, ensure the following parameters are included in the request:
*   Analyze the rule in detail
*   Follow the instructions
*   Generate a prompt
*   Include all relevant files
*   Response format: dynamic
*   Iteration: 2
*   Critic: yes
*   Set a unique session ID
*   Project Intel: true
*   No 3.5 OpenAI models
*   Use the large embedding model from OpenAI
*   Ensure a satisfactorily defined DB schema for the vector DB
*   Ensure an output schema defined for the research packages generated for storage

## OpenAI API Integration Rules (2025)

### MANDATORY PRE-RESPONSE REQUIREMENTS

**BEFORE ANY OPENAI API INTEGRATION**:

#### 1. TIME AND DATE CHECK
```python
# MANDATORY: Check current time/date at response start
from mcp_time_current_time import current_time
current_time = current_time(format="YYYY-MM-DD HH:mm:ss")
```
Date awareness is important to understand the amount of time that has elapsed since the model's knowledge cutoff date. This period of time represents the gap in knowledge the agent has of the changes, updates, and new information available regarding the available tools, software, versions, and related details those impact such as proper syntax, access methods, etc. It also means the agent is not aware of the latest concepts, techniques, or discoveries regarding how to best implement, leverage or use various techologies, tools, and related.

#### 2. ONLINE RESEARCH REQUIREMENT
- **RESEARCH CURRENT API VERSIONS**: OpenAI API changes frequently (2025 updates)
- **VERIFY MODEL AVAILABILITY**: Confirm model names and capabilities
- **CHECK SYNTAX UPDATES**: API syntax evolves rapidly (Responses API vs Chat Completions)
- **VALIDATE PRICING**: Confirm current token costs and limits
- **PROMPTING BEST PRACTICES**: Research latest model-specific optimization techniques

#### 3. EVIDENCE-BASED API SELECTION
- Base model choices on CURRENT documentation
- Verify feature availability through research
- No assumptions about API capabilities
- Test model-specific prompting strategies

### Model Selection (2025 Current Standards)

**APPROVED MODELS ONLY**: o3, o4 series, GPT-5 series
**gpt-4o series models are FORBIDDEN**
**NO GPT-3.5 MODELS**

| Use‚ÄëCase                   | Primary Model                  | Alternative         | Notes                               |
| ----- | --- | ---- | ----- |
| **Reasoning/Planning**     | `o4-mini`                      | `o3`                | MANDATORY for reasoning workflows   |
| **Agent Execution**        | `gpt-5-mini`                   | `gpt-5`             | MANDATORY for agent implementation  |
| **Structured Outputs**     | `gpt-5`                        | `gpt-5-mini`        | Required for JSON schema compliance |
| **Complex reasoning/code** | `gpt-5`, `o3`                  | `o4-mini`           | Context-dependent selection         |
| **Fast responses**         | `gpt-5-nano`, `gpt-5-mini`     | Efficiency priority |

**CRITICAL MODEL CONSTRAINTS**:
- **OAMAT-SD Application**: MUST use `o4-mini` (reasoning) and `gpt-5-mini` (agents)
- **Structured Outputs**: Use `gpt-5-mini` or `gpt-5` for JSON schema compliance
- **NO GPT-4O VARIANTS**: Only o3, o4, and GPT-5 series approved for use
- **NO GPT-3.5 MODELS**
- **Resolution**: Use appropriate model for specific requirements, document conflicts

### Latest Responses API Patterns (2025 PREFERRED)

#### Standard Responses API with Structured Outputs
```python
# ‚úÖ CURRENT STANDARD - Responses API (2025)
from openai import OpenAI
from pydantic import BaseModel
from typing import List, Optional

client = OpenAI()

# Structured Output with Pydantic
class ResponseSchema(BaseModel):
    analysis: str
    confidence: float
    recommendations: List[str]
    metadata: Optional[dict] = None

response = client.responses.create(
    model="gpt-5-mini",  # or "o4-mini" for reasoning
    instructions="You are a helpful assistant that provides structured analysis.",
    input="Analyze this data and provide recommendations...",
    text_format=ResponseSchema
)

# Access parsed response
result = response.output_parsed
```

#### Advanced Role Hierarchy (2025 BEST PRACTICE)
```python
# ‚úÖ PRIORITY ORDER: developer > user > assistant
messages = [
    {
        "role": "developer",  # HIGHEST PRIORITY
        "content": """
        ## SYSTEM CONSTRAINTS
        - Output must be valid Python code
        - Use type hints for all functions
        - Include comprehensive error handling
        - Follow PEP 8 standards strictly

        ## FORBIDDEN ACTIONS
        - Do not use deprecated libraries
        - Do not hardcode sensitive data
        - Do not skip input validation
        """
    },
    {
        "role": "user",       # MEDIUM PRIORITY
        "content": "Create a FastAPI endpoint for user authentication with JWT tokens"
    },
    {
        "role": "assistant",  # CONTEXT ONLY
        "content": "I'll help you create a secure authentication endpoint..."
    }
]

response = client.responses.create(
    model="gpt-5-mini",
    input=messages,
    text_format=CodeResponseSchema
)
```

### Model-Specific Optimization Patterns

#### **For O3/o4-mini Models (Reasoning Focus)**
```python
# ‚úÖ O3-OPTIMIZED PATTERN - Minimal, clear prompts
response = client.responses.create(
    model="o4-mini",
    instructions="You are a system architect. Design a scalable microservices architecture.",
    input="Requirements: 100k users, real-time chat, file sharing, mobile support",
    text_format=ArchitectureSchema,
    # O3-specific parameters
    reasoning_effort="high",  # thorough analysis
    verbosity="concise"       # controlled output length
)

# ‚úÖ NO CHAIN-OF-THOUGHT for O3 - they reason internally
# ‚ùå AVOID: "Think step by step...", "Let's break this down..."
```

#### **For GPT-5 Models (Execution Focus)**
```python
# ‚úÖ GPT-5-OPTIMIZED PATTERN - Detailed, explicit guidance
response = client.responses.create(
    model="gpt-5-mini",
    instructions="""
    ## PERSISTENCE
    Continue until the user's query is completely resolved.

    ## REASONING STRATEGY
    First, analyze the requirements systematically.
    Then, consider edge cases and error conditions.
    Finally, implement with comprehensive validation.

    ## OUTPUT STANDARDS
    - Include step-by-step reasoning
    - Provide code with error handling
    - Explain design decisions
    """,
    input="Build a robust API endpoint with caching and rate limiting",
    text_format=DetailedCodeSchema
)
```

### Prompt Templates and Caching (2025 OPTIMIZATION)
```python
# ‚úÖ REUSABLE PROMPT TEMPLATES
response = client.responses.create(
    model="gpt-5-mini",
    prompt={
        "id": "pmpt_code_generator_v2",
        "version": "2.1",
        "cache": True,  # Enable prompt caching
        "variables": {
            "language": "Python",
            "framework": "FastAPI",
            "task_type": "API endpoint",
            "requirements": "authentication, validation, error handling"
        }
    },
    input="Create secure user registration endpoint",
    text_format=CodeResponseSchema
)

# ‚úÖ DYNAMIC PROMPT GENERATION
def generate_prompt_variables(task_context: dict) -> dict:
    """Generate prompt variables dynamically based on context"""
    return {
        "complexity": analyze_complexity(task_context),
        "technologies": extract_technologies(task_context),
        "constraints": identify_constraints(task_context)
    }
```

### Enhanced Structured Outputs with Validation
```python
# ‚úÖ COMPREHENSIVE SCHEMA DEFINITION
from pydantic import BaseModel, Field, validator
from enum import Enum

class